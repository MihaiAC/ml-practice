{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "learning_how_to_prune.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NiM4s6e9oMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HToK1JdA2VY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import dataset (MNIST).\n",
        "\n",
        "# Transforms which will be applied to the data.\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                ])\n",
        "\n",
        "# Split the train dataset into a train + valid datasets.\n",
        "# Must set the values of the samples in each split (here, 50000, 10000).\n",
        "dataset = datasets.MNIST(root='../data', train=True, download=True, transform=transform)\n",
        "train_set, valid_set = torch.utils.data.random_split(dataset, [50000, 10000])\n",
        "\n",
        "# Load the test dataset.\n",
        "test_set = datasets.MNIST(root='../data', train=False, transform=transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zASUxJHID5jH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformations will not be applied until you call a DataLoader on it.\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = 32, shuffle=True, num_workers=0, drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=False, num_workers=0, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 32, shuffle=False, num_workers=0, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nytgp5uPJdpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a neural net.\n",
        "class LeNetTrash(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetTrash, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 300)\n",
        "        self.fc2 = nn.Linear(300, 100)\n",
        "        self.fc3 = nn.Linear(100, 10)\n",
        "    \n",
        "    def forward(self, input):\n",
        "        x = input.flatten(start_dim=1, end_dim=-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uux0VdFV9G1",
        "colab_type": "code",
        "outputId": "8a4b23f0-f4f3-4cb9-c6b1-13226b40fb55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# Instantiate the model.\n",
        "net = LeNetTrash()\n",
        "print(net)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNetTrash(\n",
            "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
            "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlBc3G2eV_VQ",
        "colab_type": "code",
        "outputId": "fe157898-2187-481b-b9ee-e4f580e56e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "# Initialise the model weights.\n",
        "def weight_init(m):\n",
        "    if(isinstance(m, nn.Linear)):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    # Other branches if other types of layers are present.\n",
        "\n",
        "# Apply the weight initialization function recursively for each layer of the net.\n",
        "net.apply(weight_init)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNetTrash(\n",
              "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
              "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ7n7ExlQORE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code for training one epoch (one pass through the dataset).\n",
        "def train_one_epoch(model, train_loader, optimizer, criterion):\n",
        "    model.train() #Sets nn.Module in train mode (has effects only on some models)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "        output = model(imgs)\n",
        "        \n",
        "        train_loss = criterion(output, targets)\n",
        "        train_loss.backward()\n",
        "\n",
        "        # In original, gradient of the pruned nodes were made 0.\n",
        "        optimizer.step()\n",
        "    \n",
        "    # train_loss is a tensor with one value;\n",
        "    # tensor.item() returns the value held by a tensor with one value;\n",
        "    return train_loss.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZLOCYsHVbq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy_and_loss(model, loader, criterion):\n",
        "    # Put the model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    nr_batches = len(loader)\n",
        "    total_loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (imgs, targets) in enumerate(loader):\n",
        "            imgs, targets = imgs.to(device), targets.to(device)\n",
        "\n",
        "            output = model(imgs)\n",
        "\n",
        "            total_loss += (1/nr_batches) * criterion(output, targets)\n",
        "\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += targets.shape[0]\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    accuracy = correct/total * 100\n",
        "    return accuracy, total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRjrcQ2ljgzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(PATH, epoch, model, optimizer):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, PATH)\n",
        "\n",
        "# model, optimizer must be instantiated objects of the same respective types\n",
        "# as the model/optimizer that were saved.\n",
        "def load_checkpoint(PATH, model, optimizer):\n",
        "    checkpoint = torch.load(PATH)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    return model, optimizer, epoch\n",
        "\n",
        "def remove_checkpoint(PATH):\n",
        "    if(os.path.exists(PATH)):\n",
        "        os.remove(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6V9y7EuveK",
        "colab_type": "code",
        "outputId": "443f8e37-2b6f-452e-c444-b73a03203336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def get_best_model_PATH(experiment_folder, best_model_filename, prune_iter):\n",
        "    return experiment_folder + '/' + best_model_filename + '_prune_iter_' + str(prune_iter) + '.tar'\n",
        "\n",
        "print(get_best_model_PATH('experiments/FC_test_run', 'best_model', 0))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "experiments/FC_test_run/best_model_prune_iter_0.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2YWV5CoZm5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a pruning strategy for the layers of the model.\n",
        "# prune_methods must contain a mapping from modules names to pruning methods.\n",
        "# prune_args must contain a mapping from modules names to the arguments of the\n",
        "# respective pruning methods.\n",
        "def prune_model(model, prune_method, prune_args):\n",
        "    for name, module in model.named_modules():\n",
        "        prune_method[name](module, **prune_args[name])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1bThPJoeMz",
        "colab_type": "code",
        "outputId": "ec26c74f-1e4d-4554-a4c0-b6bed96de48e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def restore_orig_weights(model):\n",
        "    for name, module in model.named_modules():\n",
        "        \n",
        "        #print(list(module.named_parameters()))\n",
        "        #print(dict(module.named_buffers()).keys())\n",
        "        if(name == ''):\n",
        "            continue\n",
        "        print('\\n\\n\\n')\n",
        "        print(name + str(type(module)))\n",
        "        print(module.weight)\n",
        "        #for parameter_name, parameter in module.named_parameters():\n",
        "        #    print(parameter_name + ' ' + str(type(parameter)))\n",
        "restore_orig_weights(net)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "fc1<class 'torch.nn.modules.linear.Linear'>\n",
            "Parameter containing:\n",
            "tensor([[ 0.0222,  0.0469,  0.0494,  ...,  0.0173, -0.0053,  0.0220],\n",
            "        [ 0.0992,  0.0046, -0.0264,  ..., -0.0449, -0.0249,  0.0866],\n",
            "        [-0.0044,  0.0049, -0.0662,  ..., -0.0534, -0.0521,  0.0599],\n",
            "        ...,\n",
            "        [ 0.0701, -0.0238, -0.0836,  ...,  0.0071,  0.0211, -0.0638],\n",
            "        [-0.0789,  0.0138, -0.0051,  ...,  0.0111, -0.0370,  0.0138],\n",
            "        [ 0.0094,  0.0133, -0.0426,  ...,  0.0109, -0.0360,  0.0143]],\n",
            "       requires_grad=True)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fc2<class 'torch.nn.modules.linear.Linear'>\n",
            "Parameter containing:\n",
            "tensor([[ 4.5328e-02, -5.3506e-02,  5.0311e-03,  ..., -1.9942e-02,\n",
            "         -2.8242e-02,  8.6791e-02],\n",
            "        [ 2.4255e-02,  1.2922e-02,  6.4602e-02,  ..., -1.9510e-02,\n",
            "         -8.2361e-02, -1.2523e-01],\n",
            "        [-8.3200e-02,  9.2748e-02,  1.2278e-01,  ..., -1.8978e-02,\n",
            "         -1.0114e-01, -6.0964e-03],\n",
            "        ...,\n",
            "        [ 1.8643e-01, -9.5648e-03, -5.3288e-02,  ..., -1.3616e-02,\n",
            "          9.1870e-02, -7.6701e-02],\n",
            "        [-1.4592e-02,  5.3188e-02,  1.2231e-01,  ..., -3.0432e-02,\n",
            "         -5.2523e-05,  1.7000e-01],\n",
            "        [ 6.7972e-03,  4.8108e-03,  5.6408e-02,  ..., -5.1954e-02,\n",
            "         -7.2318e-02,  3.1509e-02]], requires_grad=True)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fc3<class 'torch.nn.modules.linear.Linear'>\n",
            "Parameter containing:\n",
            "tensor([[ 5.4461e-02,  6.1645e-03,  1.6174e-01, -1.9976e-02, -1.3356e-01,\n",
            "         -1.0971e-02, -8.3744e-02, -4.3333e-02, -4.0045e-02,  1.4725e-01,\n",
            "         -6.3293e-03, -5.3348e-03, -2.2601e-01, -9.5483e-02, -1.5745e-01,\n",
            "         -8.5629e-02,  1.2390e-01,  6.7568e-02, -3.5204e-03, -2.1789e-02,\n",
            "         -1.2958e-03,  3.0862e-02, -1.2331e-01,  1.8352e-01,  2.2945e-02,\n",
            "         -1.1534e-01,  2.5278e-01, -4.9623e-02, -1.1018e-01, -1.9988e-02,\n",
            "          6.7781e-02, -2.0068e-01, -1.7456e-01,  3.3878e-01,  2.2461e-01,\n",
            "          1.0700e-01,  9.9906e-02,  3.2640e-02, -1.9335e-02, -9.7553e-02,\n",
            "         -6.3647e-02,  2.8586e-01, -2.0448e-01, -4.2534e-03, -2.0053e-01,\n",
            "         -1.5922e-01,  2.2101e-01,  3.5767e-02,  2.8652e-02,  1.2991e-01,\n",
            "         -1.5076e-01, -6.4217e-02, -6.7448e-02, -1.5828e-01, -7.7410e-03,\n",
            "         -2.5387e-01, -7.8937e-02,  2.8132e-02,  1.8934e-01, -1.0263e-01,\n",
            "          1.1187e-01,  4.5138e-02,  1.3652e-01, -2.2895e-01, -1.4232e-01,\n",
            "         -1.2416e-01,  1.7447e-01,  1.9222e-02,  3.1160e-02,  2.9706e-02,\n",
            "          1.5392e-01, -9.3291e-02,  5.1422e-02,  9.5964e-02, -1.5982e-01,\n",
            "         -1.1118e-01,  3.3707e-02,  2.3829e-01, -1.2296e-01,  1.5130e-01,\n",
            "          4.9223e-02,  8.7489e-02,  1.8736e-01,  1.7564e-02,  1.0652e-01,\n",
            "          2.0571e-01,  1.5943e-01,  2.5037e-02, -7.6622e-02, -1.3464e-01,\n",
            "          1.6456e-02,  2.2160e-01, -3.8597e-02,  2.1807e-01, -2.1013e-02,\n",
            "          6.1608e-02,  1.7005e-01,  6.4219e-02, -2.0805e-01,  2.2725e-01],\n",
            "        [ 1.1734e-01, -5.3423e-02,  1.2488e-01,  1.9572e-01,  1.0537e-01,\n",
            "         -6.0047e-02, -9.7868e-02, -1.5233e-01,  1.5912e-02, -4.0201e-02,\n",
            "          9.9495e-03, -7.9967e-02, -1.2571e-01, -3.0433e-01,  1.3334e-01,\n",
            "          3.2352e-02, -1.7479e-01,  1.0856e-01,  1.4134e-02, -3.4196e-02,\n",
            "         -2.0020e-01,  3.2462e-02,  1.2831e-01,  1.0213e-01, -1.4674e-01,\n",
            "          9.1119e-02,  7.6276e-02,  1.0006e-01, -2.8782e-01, -4.6818e-02,\n",
            "          4.5871e-02, -1.5874e-01,  9.1165e-02, -4.5979e-02, -1.2636e-01,\n",
            "          1.6008e-01,  1.0365e-01,  4.6655e-02, -2.7314e-03,  1.0878e-01,\n",
            "         -1.3642e-02,  1.2563e-01,  1.8910e-01,  2.8419e-01,  9.6441e-02,\n",
            "          7.2361e-02,  6.5960e-02, -2.3586e-01,  1.3380e-01, -1.2009e-01,\n",
            "          2.9192e-02, -3.9802e-02,  7.3883e-02, -4.5566e-02, -2.9254e-02,\n",
            "         -2.5783e-01,  1.2897e-01,  2.1184e-01, -1.3569e-01,  8.8214e-03,\n",
            "          1.4648e-01,  2.1678e-01,  1.1940e-01, -1.0655e-01, -1.7422e-01,\n",
            "          7.6539e-02, -3.7052e-02, -2.5572e-02, -3.6318e-02, -5.0577e-02,\n",
            "         -8.8923e-02,  4.7845e-02,  2.2651e-01, -1.2567e-01, -4.3288e-02,\n",
            "         -2.4886e-02,  3.8789e-02, -2.3884e-02,  2.9011e-01, -1.2309e-01,\n",
            "         -1.5356e-01, -1.5916e-01, -5.0931e-02, -2.9735e-02, -3.1249e-01,\n",
            "         -5.0241e-02, -1.9514e-04,  1.5762e-01, -2.0536e-02,  1.8047e-01,\n",
            "          1.0565e-01, -5.1371e-02, -4.7405e-02,  6.1310e-02, -6.7889e-02,\n",
            "          9.4013e-02,  8.9832e-02, -7.4126e-02, -7.2450e-03,  1.4645e-02],\n",
            "        [-5.1669e-02, -6.1739e-03,  1.5490e-01,  1.1384e-01,  3.1395e-01,\n",
            "          4.5043e-02,  4.0788e-02,  1.8548e-02,  1.7540e-01, -7.3972e-02,\n",
            "         -1.0061e-01,  4.9145e-02,  9.9028e-02,  1.9215e-01, -1.7492e-01,\n",
            "         -2.7083e-01, -5.3654e-02,  2.1480e-01, -7.5849e-02,  1.7913e-02,\n",
            "          5.8605e-02,  3.0231e-02,  8.7106e-05, -1.0346e-01,  4.1912e-02,\n",
            "          5.4792e-02,  1.0645e-01,  2.8240e-01,  1.9186e-01, -1.9545e-01,\n",
            "          5.0832e-02, -4.0811e-02, -1.4238e-01,  2.7303e-01, -2.3508e-01,\n",
            "         -2.9364e-01, -3.8437e-01,  1.9006e-02, -2.0712e-02, -1.9121e-01,\n",
            "         -6.8794e-02,  2.5192e-02,  1.2369e-01, -3.1927e-03, -1.0910e-01,\n",
            "         -3.3137e-01, -2.2136e-02, -8.3718e-02, -4.4920e-02,  9.7427e-02,\n",
            "          3.3135e-02, -6.7573e-02,  1.0452e-01,  5.8678e-02, -6.8253e-02,\n",
            "          2.8268e-01,  1.0536e-01,  2.9636e-02,  6.5778e-02, -1.0191e-01,\n",
            "          1.3719e-01,  1.9802e-01,  3.1157e-01,  5.3302e-02,  7.1032e-02,\n",
            "          7.2445e-02, -6.4854e-02,  1.8417e-01,  9.3475e-02,  1.0206e-01,\n",
            "          2.8244e-01, -6.9998e-02,  3.0112e-02, -1.0956e-01, -2.1859e-01,\n",
            "          8.1240e-02, -7.4104e-02,  8.2054e-02,  6.8965e-02,  2.1514e-03,\n",
            "         -1.3063e-01, -2.2769e-01,  1.6852e-01,  1.3744e-01,  9.5788e-02,\n",
            "         -2.7108e-01, -2.7343e-01,  2.4564e-01,  3.7919e-02, -1.8461e-01,\n",
            "         -1.9159e-01,  5.6038e-03,  2.3033e-02,  2.1769e-01, -1.3158e-01,\n",
            "         -1.7682e-01, -2.4244e-02, -3.5420e-03, -7.5164e-02,  7.4200e-02],\n",
            "        [-1.5143e-02,  1.2516e-01, -1.3984e-01,  1.0066e-01, -1.9341e-01,\n",
            "         -1.6648e-01,  8.2526e-02,  9.9670e-02, -1.6598e-01,  3.0105e-02,\n",
            "          7.9948e-02,  1.7395e-01,  1.1696e-01,  3.0453e-02, -2.0816e-01,\n",
            "         -8.5857e-02, -2.9467e-03, -7.4279e-02,  3.9063e-01,  3.3229e-02,\n",
            "         -1.6204e-01,  1.1505e-01,  1.2670e-01, -7.6464e-02, -1.1089e-02,\n",
            "         -7.6311e-02,  2.6644e-01, -1.4782e-01, -1.9789e-01,  1.3936e-01,\n",
            "         -3.0383e-02,  9.4073e-02, -4.2444e-02, -4.2160e-02,  1.9321e-01,\n",
            "          3.3347e-01,  3.2103e-02, -1.6775e-02,  2.6911e-01, -2.5153e-02,\n",
            "          5.9280e-03, -1.0377e-01,  5.7075e-02, -3.0808e-02,  2.1945e-01,\n",
            "          1.8355e-02,  1.6931e-02, -3.2702e-02, -1.3973e-02, -1.0541e-01,\n",
            "          9.7908e-02, -8.5719e-02,  5.4714e-02, -2.3533e-01,  2.3565e-01,\n",
            "          8.0625e-02, -7.5694e-02, -1.7351e-01, -2.1112e-01, -3.7184e-02,\n",
            "         -8.4482e-04,  4.5413e-02,  1.6052e-01, -7.8583e-02, -1.2117e-01,\n",
            "          1.0179e-01, -1.8268e-01,  5.5630e-02,  1.4683e-01,  3.4358e-03,\n",
            "         -8.1876e-02, -2.4986e-01, -2.2359e-01,  3.0382e-01, -2.0412e-01,\n",
            "          1.8615e-01, -9.7463e-02,  1.8925e-01, -3.4252e-02,  4.3408e-02,\n",
            "         -2.3640e-02,  1.5952e-01,  1.7299e-01, -3.1081e-01, -9.8650e-02,\n",
            "         -5.5091e-02,  1.9332e-01, -4.2505e-02,  2.0267e-01,  1.0364e-01,\n",
            "          9.8706e-02, -1.4973e-01, -4.8539e-02, -5.6428e-02,  9.3786e-02,\n",
            "         -2.6787e-01, -4.1500e-02,  2.5579e-01,  3.2199e-02, -1.1915e-01],\n",
            "        [ 8.7537e-02,  2.9674e-02,  1.4946e-01,  1.0945e-01,  1.5297e-02,\n",
            "          1.4916e-01, -2.0644e-02,  4.9446e-02,  1.7755e-01, -1.1224e-01,\n",
            "         -2.0985e-01,  3.0294e-02, -1.1395e-02,  7.6325e-02, -1.1252e-01,\n",
            "         -1.7572e-01,  1.2932e-02,  2.4702e-02, -1.3649e-01, -1.1586e-01,\n",
            "         -3.5670e-01, -2.6228e-02, -2.0700e-02,  1.1141e-01, -8.9882e-02,\n",
            "         -6.6512e-02,  2.7685e-02, -9.1884e-02, -9.0486e-02, -1.0339e-01,\n",
            "         -7.2864e-02,  4.4958e-02, -1.0364e-01,  4.8913e-02,  3.3067e-03,\n",
            "          3.9206e-02,  1.3681e-01, -9.0396e-02,  1.4543e-01, -3.7236e-02,\n",
            "          1.1029e-01,  1.9901e-01, -7.6160e-02,  1.1203e-01, -5.9618e-02,\n",
            "         -8.4007e-02,  1.8575e-02, -1.4958e-01, -1.7715e-02,  2.9365e-02,\n",
            "         -1.5395e-01, -3.4568e-02, -1.8172e-01, -9.3724e-02, -6.2578e-02,\n",
            "         -3.6355e-02, -1.2798e-01,  2.9222e-01, -8.8780e-02, -2.5053e-02,\n",
            "         -3.6984e-02,  1.9152e-01,  4.3955e-02,  7.9708e-02, -3.1991e-02,\n",
            "         -8.5126e-02,  1.2300e-01, -3.7300e-02, -3.4428e-02,  1.1458e-01,\n",
            "         -1.6534e-01, -8.2943e-03,  9.0051e-03, -7.0368e-02,  1.7917e-02,\n",
            "         -3.2188e-02,  3.5679e-02,  1.3847e-01, -7.2023e-02,  6.4051e-02,\n",
            "          8.4401e-02,  5.6189e-02, -9.2049e-03,  1.1237e-01, -2.6158e-01,\n",
            "         -4.2331e-02, -1.2022e-01, -1.4746e-01, -8.2885e-02, -9.1964e-02,\n",
            "         -2.8238e-01,  7.6588e-02,  1.1388e-01,  1.6094e-02,  1.0396e-01,\n",
            "          1.1107e-01, -1.4616e-01, -1.8920e-01,  6.6366e-02, -8.9159e-02],\n",
            "        [-5.2245e-02,  1.1892e-01,  8.6620e-02,  2.6037e-02,  1.0999e-01,\n",
            "          1.0641e-01,  1.9633e-01, -4.0726e-02, -1.1961e-01, -6.5920e-02,\n",
            "         -1.9890e-01, -1.3280e-01,  8.3598e-02,  2.0250e-01, -1.8174e-01,\n",
            "         -1.0043e-01,  1.0407e-01, -1.4797e-01, -8.7970e-02,  2.5189e-02,\n",
            "         -3.8849e-02, -2.5313e-01,  2.9919e-01, -1.0531e-01,  2.0919e-01,\n",
            "         -2.9216e-01,  1.5307e-01, -4.2341e-03, -1.5215e-01,  2.2748e-02,\n",
            "          1.5277e-01,  3.5225e-02, -2.8746e-01, -1.1457e-01,  7.3117e-02,\n",
            "         -8.0474e-02, -1.3308e-01,  1.7996e-01, -1.0111e-01, -6.9123e-02,\n",
            "         -1.0331e-01, -1.5049e-01, -1.2122e-01,  9.9192e-02, -1.6239e-01,\n",
            "         -1.8112e-01,  1.7519e-01, -1.3040e-01,  1.2808e-01, -2.4658e-01,\n",
            "         -5.4808e-02,  9.3038e-02,  2.1330e-01, -5.4250e-02, -1.9084e-03,\n",
            "         -5.5707e-02, -1.0174e-01, -1.3146e-01,  1.2435e-01,  1.3999e-01,\n",
            "         -4.9753e-02,  8.5014e-02, -1.4594e-01, -2.2178e-01,  2.3248e-01,\n",
            "          1.9922e-02, -1.2036e-01,  1.5351e-02, -1.2854e-02, -2.9000e-03,\n",
            "          8.7173e-02, -2.3144e-01, -2.5646e-01,  1.0758e-01,  3.4986e-02,\n",
            "          1.4210e-01, -1.2561e-01,  5.5158e-02, -1.6366e-01, -2.8311e-02,\n",
            "         -1.7048e-01, -5.5892e-02,  1.6289e-01,  8.7950e-02,  1.2522e-01,\n",
            "          1.0097e-02,  2.0134e-01, -8.6457e-02, -3.1063e-02, -3.3814e-02,\n",
            "         -9.5644e-03,  1.0978e-01, -4.9289e-02, -8.2096e-02, -1.4058e-01,\n",
            "          3.6864e-02, -1.9121e-02, -2.0509e-01,  2.9359e-02, -1.0429e-01],\n",
            "        [-6.9792e-02, -2.1793e-02,  7.9070e-02,  1.6292e-01,  1.6337e-02,\n",
            "         -2.4666e-02,  2.1098e-01,  2.0462e-01, -1.3696e-01, -9.8593e-02,\n",
            "          8.8432e-02, -1.9046e-01, -1.9032e-01, -5.2214e-02, -2.5913e-01,\n",
            "         -5.1675e-02,  1.1269e-01, -5.3183e-02, -2.8705e-02,  3.0256e-01,\n",
            "         -1.1249e-01,  1.4303e-01,  1.0610e-01,  1.9148e-01,  7.0609e-02,\n",
            "          7.2890e-02, -1.9708e-01, -1.7872e-01, -7.4668e-02,  5.1476e-02,\n",
            "         -1.1079e-01,  3.1632e-01,  1.2175e-01, -7.8889e-02, -1.9475e-02,\n",
            "          2.6455e-02, -4.3461e-02,  3.7091e-02,  1.2168e-01, -2.5600e-01,\n",
            "         -3.1308e-01, -1.3844e-01,  3.4886e-02,  4.2688e-02, -4.0484e-02,\n",
            "         -1.7157e-01,  1.0010e-01, -1.5714e-01, -1.3755e-01, -9.9272e-02,\n",
            "         -2.5738e-01,  2.7005e-01,  7.7456e-02,  3.3994e-03,  5.6421e-02,\n",
            "          1.1800e-01, -1.6413e-01,  8.5622e-02, -9.6871e-02,  1.0589e-01,\n",
            "          7.0963e-02,  3.6424e-02,  5.9720e-02,  1.4410e-01, -1.2354e-01,\n",
            "          6.2086e-02,  5.0125e-02,  1.1751e-01,  1.4610e-01, -9.2854e-02,\n",
            "          4.3033e-02, -1.1955e-01,  2.3858e-01,  1.8172e-01, -4.4396e-02,\n",
            "         -7.2873e-02,  5.3575e-02, -4.6389e-02,  3.3940e-02, -2.4751e-02,\n",
            "         -1.7814e-01,  1.5585e-01, -1.1436e-01,  9.7952e-02,  1.4772e-01,\n",
            "         -7.7041e-02, -1.5734e-01,  5.0788e-02, -9.5495e-02, -2.8716e-02,\n",
            "          3.7872e-03,  5.9967e-02,  1.2890e-01, -5.9396e-02, -4.3515e-02,\n",
            "          8.8634e-02,  2.9547e-02,  2.1949e-01,  9.4790e-02, -2.2545e-01],\n",
            "        [-2.0474e-01,  5.1485e-02,  1.0205e-02, -7.3112e-03,  9.5749e-02,\n",
            "          7.6540e-02,  2.7067e-02, -2.0829e-01, -2.2886e-01, -1.1546e-02,\n",
            "          6.2064e-02,  3.0324e-02, -1.0226e-01,  1.6358e-02,  2.1429e-02,\n",
            "          1.2128e-01,  2.1262e-01, -5.0243e-02,  8.1809e-02, -9.2648e-02,\n",
            "          4.7979e-03, -9.7399e-02,  7.1941e-02, -2.5021e-02,  1.0286e-01,\n",
            "         -1.1794e-01, -1.8905e-01,  4.8358e-02,  1.5135e-01,  2.1183e-01,\n",
            "         -1.6901e-01, -8.9941e-02,  9.7921e-03,  1.5066e-01, -1.2623e-01,\n",
            "          3.1493e-02,  1.0595e-02, -1.8185e-01,  8.6691e-02,  1.6448e-02,\n",
            "         -1.3543e-01, -1.3072e-02,  2.1702e-01,  2.0771e-01, -1.4703e-01,\n",
            "          1.5987e-01,  4.2321e-02,  1.3508e-02,  5.6932e-02, -1.2083e-01,\n",
            "         -3.4861e-01, -7.3048e-02,  2.5876e-01,  9.3605e-03,  1.8631e-01,\n",
            "         -1.2329e-01, -3.5638e-01, -1.5106e-01,  3.6169e-02,  3.0674e-01,\n",
            "         -4.0661e-02, -3.1077e-01, -6.9152e-02, -7.1462e-02,  8.9453e-02,\n",
            "         -8.2878e-02,  1.4175e-01,  7.6239e-02, -9.3755e-02,  1.7736e-01,\n",
            "         -1.3202e-01, -1.0564e-02,  1.6389e-01,  7.5081e-02,  1.7854e-01,\n",
            "         -1.6572e-01, -1.6532e-01,  2.5469e-01,  2.0502e-01, -2.4746e-01,\n",
            "          8.2017e-02,  2.3433e-01,  1.9491e-01,  2.1968e-02, -2.8499e-01,\n",
            "          2.2483e-01,  1.4624e-01,  1.7504e-02, -3.3084e-02,  2.5353e-01,\n",
            "         -2.4658e-02,  6.7283e-03, -1.7799e-01,  1.4077e-01, -3.0238e-02,\n",
            "         -2.7979e-01, -5.7191e-02,  1.6504e-01, -6.7303e-02, -6.2496e-02],\n",
            "        [ 9.9100e-02, -2.4272e-02, -9.0184e-03, -5.6033e-02,  6.8439e-02,\n",
            "         -3.3175e-01,  8.5916e-02, -1.4153e-01,  8.3376e-03,  1.1620e-01,\n",
            "          6.4887e-02, -4.9216e-02,  5.6938e-02,  1.8293e-01,  8.9177e-02,\n",
            "          1.7213e-01, -6.7753e-02,  2.9811e-03,  1.3429e-01,  2.6080e-01,\n",
            "          5.2577e-02,  1.9703e-02, -9.0905e-02,  2.7928e-02,  5.5621e-02,\n",
            "         -1.0585e-01, -9.3070e-03,  6.1618e-02, -5.5034e-02, -2.6879e-02,\n",
            "         -2.5453e-01,  6.8056e-02,  8.0495e-03,  2.0480e-01, -3.9180e-02,\n",
            "          1.5946e-01,  1.1106e-01,  1.0614e-01, -1.7243e-01,  1.4864e-01,\n",
            "         -1.5781e-01,  2.1407e-02,  2.1057e-01, -2.5701e-01,  9.6206e-02,\n",
            "         -6.8294e-02, -2.4607e-03, -1.7631e-01,  1.2541e-02,  8.4299e-02,\n",
            "         -1.1967e-01,  2.0915e-01, -2.1609e-02,  1.4561e-01,  1.8544e-01,\n",
            "          2.5333e-03,  6.1414e-02, -4.1543e-01, -6.7012e-02, -1.2011e-01,\n",
            "         -4.1826e-02,  4.3789e-02, -7.3145e-02,  1.7207e-01, -2.2415e-02,\n",
            "          2.2678e-02, -8.6127e-03, -3.5616e-02,  1.7063e-01, -4.0126e-02,\n",
            "         -4.7741e-02,  5.9267e-02,  1.9443e-02,  1.0804e-01,  6.1694e-02,\n",
            "         -7.3025e-02, -4.1751e-02,  2.3525e-01, -5.4962e-02,  5.3535e-02,\n",
            "         -8.5579e-03,  4.2590e-02,  3.3715e-02,  3.1776e-01, -1.8203e-02,\n",
            "          1.6781e-01,  2.2593e-01, -3.5733e-02, -1.1346e-01,  1.7162e-01,\n",
            "          3.9839e-01,  3.6421e-02, -1.6246e-01, -1.3049e-01,  2.4229e-01,\n",
            "          2.3286e-01, -2.3489e-02,  2.9495e-01, -1.2878e-01,  1.9531e-01],\n",
            "        [-6.4893e-02,  6.8920e-02, -1.3822e-02,  3.2361e-02, -5.3672e-02,\n",
            "          7.6072e-02,  3.0065e-02, -6.6749e-02,  2.6934e-01,  2.4792e-02,\n",
            "          3.8999e-02, -5.9442e-02,  2.5286e-01,  1.8802e-01,  2.0902e-01,\n",
            "          1.1161e-01,  1.0086e-01,  3.0787e-02, -5.7390e-03, -4.0438e-02,\n",
            "         -7.8755e-02,  2.0460e-01,  1.6133e-01, -1.3532e-02, -3.1742e-01,\n",
            "         -5.0626e-02,  1.4726e-01,  1.4083e-01,  1.6773e-02, -5.2298e-02,\n",
            "          1.5463e-01,  1.7693e-01,  1.7823e-02,  5.3280e-02,  1.2848e-01,\n",
            "          7.5924e-02, -1.7058e-01,  7.2205e-02,  5.1964e-02, -7.2976e-02,\n",
            "          1.5322e-01,  8.5177e-02, -2.1058e-01, -1.1474e-01, -2.0417e-02,\n",
            "         -1.8774e-01, -1.0570e-01,  4.3620e-02, -2.0505e-01, -1.4942e-01,\n",
            "         -1.4682e-02, -4.1904e-02,  2.2733e-02, -2.9089e-01,  5.1547e-02,\n",
            "         -6.8430e-02, -2.3047e-01,  3.6401e-02,  1.3744e-01, -3.2720e-02,\n",
            "          4.9702e-05, -1.1583e-02,  6.0471e-02,  1.5020e-01,  6.6842e-02,\n",
            "         -1.4889e-01, -4.0900e-02, -6.9268e-02,  1.4241e-01,  1.1410e-01,\n",
            "         -2.9740e-02, -1.7815e-01, -9.2389e-03, -3.2105e-02,  2.1946e-01,\n",
            "         -1.5069e-01, -6.1442e-02,  1.0669e-01, -1.8712e-01,  2.2219e-01,\n",
            "         -2.4746e-01,  3.0920e-01, -1.0834e-02,  1.7897e-01,  1.7170e-02,\n",
            "          3.4051e-02,  1.0654e-01, -9.1108e-02,  9.9605e-02,  2.4274e-02,\n",
            "          4.0346e-04,  2.5717e-03, -2.1038e-01,  3.2678e-02,  4.5535e-02,\n",
            "         -5.8536e-02, -1.2801e-01, -1.5257e-01, -7.0898e-02,  1.6786e-01]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CQpw9L5-HOr",
        "colab_type": "code",
        "outputId": "f0cd097e-b8e8-4492-dbaa-e52cc6c43ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(net.state_dict().keys())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNqTEetB3b_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80d6fbd9-28f3-4127-e6cc-aeee406f5787"
      },
      "source": [
        "list(net.parameters())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.0009,  0.0425,  0.0261,  ...,  0.0066,  0.0240, -0.0359],\n",
              "         [ 0.0507, -0.0170, -0.0142,  ...,  0.0015, -0.0572, -0.0091],\n",
              "         [-0.0427, -0.0477,  0.0192,  ..., -0.0263,  0.0187,  0.0216],\n",
              "         ...,\n",
              "         [-0.0842, -0.0107,  0.0155,  ...,  0.0940,  0.1008, -0.0216],\n",
              "         [ 0.0334, -0.0214,  0.0110,  ..., -0.0394,  0.0147,  0.0060],\n",
              "         [ 0.0098,  0.0278,  0.0219,  ..., -0.0508, -0.0205,  0.0089]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([ 0.1604,  1.0814,  1.2004, -0.9492, -1.2613, -0.6145, -0.2033,  1.0035,\n",
              "         -1.1604,  0.3370, -0.0480,  0.7957,  0.5526,  1.7292,  0.6536, -0.1919,\n",
              "          1.3983,  1.0776,  0.4900,  0.4933, -1.1510, -1.2824, -0.2843,  1.6931,\n",
              "          1.3025, -0.1345, -0.4162,  0.6173, -0.3863,  1.1685,  0.0172, -1.1021,\n",
              "          1.1570, -1.2995,  1.4132,  0.3960,  0.1702, -0.3318, -0.4430, -1.6753,\n",
              "          0.5717, -1.2890, -1.5643, -1.8697,  0.8611, -0.0628,  0.3078,  0.0175,\n",
              "         -1.0722,  0.4054,  0.2212, -2.1700, -1.0376,  1.0958, -0.4341, -0.7396,\n",
              "         -0.2094, -0.9316, -1.4963,  1.3527, -0.9757, -1.7810,  2.2741,  1.0771,\n",
              "          1.1006,  0.9765, -0.8550, -0.2387,  0.7776, -1.4638, -0.1156,  0.8483,\n",
              "         -0.4240,  0.8393,  0.1709, -0.0594,  0.0200, -0.1636,  0.1223,  0.7015,\n",
              "          0.3468,  0.3580, -0.6766, -0.6539, -0.3184, -0.3664,  0.8543, -0.4747,\n",
              "          0.2130,  0.4037,  0.0453,  0.6958, -0.2767,  2.0023, -0.7421, -0.3086,\n",
              "          0.3690,  1.1113, -0.8644, -0.5415,  0.7816, -0.2309,  1.7040, -0.8077,\n",
              "         -1.2715, -0.6697, -0.1052,  1.0809,  0.6945,  1.5250, -0.8526, -0.8556,\n",
              "         -1.9892, -1.3868,  1.0744, -1.0228,  1.6232,  1.5577, -0.1667, -1.6091,\n",
              "          0.0633,  0.2721, -0.6034, -1.2147, -0.5573,  0.1263,  1.0959,  0.8676,\n",
              "         -0.4523, -0.8121, -0.8349,  0.3774,  1.1059,  0.9130, -0.9724,  0.6186,\n",
              "          0.0127,  2.4302,  1.2086,  0.9921,  0.6528, -1.3362,  0.1187, -0.3691,\n",
              "         -0.2979, -0.0959, -0.5699,  0.1623, -0.0769,  0.8716,  1.8276, -0.2869,\n",
              "          0.5790,  0.0835, -0.3347, -0.3586, -0.6852, -0.3084,  0.5385, -1.2457,\n",
              "         -0.4020,  0.0316,  1.3725, -1.0447,  1.2220,  0.6869, -0.5405, -0.8815,\n",
              "          1.1358,  0.1831,  0.2574,  0.5568, -0.6896, -1.1982, -0.9645, -0.4590,\n",
              "         -1.0311,  2.4777, -0.8395, -0.7580,  1.5959,  1.2902, -0.5583, -0.1156,\n",
              "          0.5955,  2.4074,  1.3061, -1.6811,  0.2480,  1.6482, -0.3837, -0.7196,\n",
              "          1.5447,  0.1214,  1.3952, -0.3875, -1.3422, -0.1457,  0.0212,  1.4614,\n",
              "          0.6480, -0.3880, -1.3720,  0.4682, -0.5771,  0.4763, -0.2000,  1.7980,\n",
              "         -0.0803, -1.0553, -0.4328, -0.3101, -0.3883, -0.5758,  2.2178,  0.2272,\n",
              "          0.8928,  0.6888,  0.8848,  1.3061, -1.4963, -0.3661,  1.8511,  1.1373,\n",
              "         -0.4912,  0.7185, -1.8756,  0.2284, -1.2834,  0.4371,  0.8920,  1.0347,\n",
              "         -1.0392, -0.0092,  1.3431,  3.0203,  1.3312,  0.1749,  1.6327, -0.4149,\n",
              "         -0.7175,  2.1179, -1.0917,  0.1123,  0.2849,  0.7529,  0.9887, -0.8637,\n",
              "         -1.7844,  0.9788, -0.8188,  0.5371, -0.5794, -1.9668, -1.0938, -0.4630,\n",
              "         -1.0716, -0.2233,  1.3697, -1.0636,  0.1227, -0.8732, -1.0512, -1.6891,\n",
              "         -0.6393, -0.4167,  1.6520, -0.2528,  1.0727, -0.1102, -0.0244,  0.8353,\n",
              "          1.9083,  0.4697,  1.3535, -1.2846, -0.0329, -1.1439,  1.0051, -0.2880,\n",
              "         -0.8634, -0.4387, -0.0226,  0.2185,  0.8609, -0.2373,  0.9108,  0.4830,\n",
              "         -0.7011, -0.0144, -1.0596, -0.6518, -1.0385,  1.5285,  1.5623,  0.6381,\n",
              "          0.2562, -0.5483,  1.9395, -0.4647], requires_grad=True), Parameter containing:\n",
              " tensor([[ 0.0041, -0.0423, -0.0203,  ...,  0.0126, -0.0504, -0.0681],\n",
              "         [-0.0607, -0.0390,  0.0199,  ..., -0.0636,  0.0124, -0.0298],\n",
              "         [-0.0675, -0.0387, -0.0418,  ..., -0.1116,  0.0252, -0.0693],\n",
              "         ...,\n",
              "         [-0.0813, -0.0163, -0.0209,  ..., -0.0760, -0.0497, -0.0062],\n",
              "         [ 0.0107, -0.0298,  0.1060,  ...,  0.0004,  0.0451, -0.0483],\n",
              "         [ 0.0354, -0.0729,  0.1265,  ...,  0.1150,  0.0863, -0.1032]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([ 1.9754, -1.3944, -0.3482,  1.0532,  0.8050, -0.0770,  0.0863,  0.2060,\n",
              "          0.3647, -0.5103,  0.6930,  0.8413, -0.1132,  1.9959, -0.2087, -0.5788,\n",
              "          1.6279,  1.7479,  1.5081, -1.7952, -1.6041,  0.2591, -0.2347,  0.1251,\n",
              "         -1.1530,  1.9613, -1.0900, -0.8921,  0.7842, -0.8887, -0.7828, -0.6719,\n",
              "         -0.2544,  1.2134, -1.2656, -0.2365,  0.0028, -1.3733, -2.6484,  0.1179,\n",
              "          0.0618, -1.1419, -1.0314,  0.1746,  0.7708, -0.5128, -1.1163,  0.4942,\n",
              "         -0.1876, -0.8914,  0.0174,  2.6385,  0.7345, -1.1895,  1.4654,  0.2288,\n",
              "         -0.1115, -0.0400, -0.5687,  0.1320, -0.4781,  0.8525, -0.4777, -0.0376,\n",
              "          0.2233, -0.6014, -0.4767, -0.4680, -1.2628, -2.2365, -0.3158, -0.9775,\n",
              "         -0.4364,  1.3470, -0.0598,  0.8574,  1.0617, -0.9044, -1.7661, -1.4539,\n",
              "          0.9783, -0.6082, -0.4645, -0.1290, -0.4697,  0.7558,  0.0082, -0.0095,\n",
              "          1.0626,  0.9802, -0.2273, -0.9902,  0.6404, -0.4269,  0.1480,  1.2774,\n",
              "          0.6045,  0.6216,  0.7550, -0.6771], requires_grad=True), Parameter containing:\n",
              " tensor([[ 8.8242e-02, -1.4519e-01,  1.5612e-01,  7.6214e-02, -5.4089e-02,\n",
              "          -5.4557e-03, -4.9152e-02,  1.6281e-01,  2.9737e-01, -4.2330e-02,\n",
              "          -4.4721e-02, -1.1367e-02,  1.0061e-01, -1.4532e-02,  1.7156e-02,\n",
              "          -1.9671e-01, -6.0185e-02,  1.8398e-01, -2.9339e-02,  2.3175e-01,\n",
              "          -8.2981e-02,  4.5981e-02, -9.3089e-02, -1.7476e-01,  1.6690e-01,\n",
              "           9.3954e-02, -2.2814e-01,  1.7049e-01,  7.2125e-02,  1.9487e-02,\n",
              "          -2.8657e-02,  4.6983e-02, -4.5548e-02,  4.2280e-02,  2.4718e-01,\n",
              "           4.1656e-02,  8.8485e-02,  6.7054e-02, -1.8838e-01,  6.4013e-02,\n",
              "           1.8329e-02, -1.7864e-01, -1.4095e-01, -2.0330e-03, -9.9193e-02,\n",
              "          -6.8360e-03, -1.8470e-02, -8.1649e-02,  7.1760e-02,  1.5939e-01,\n",
              "          -2.1785e-01,  1.1871e-01,  2.3401e-02, -1.4620e-01, -1.1738e-01,\n",
              "          -2.5324e-01,  1.5639e-03,  8.2526e-02, -1.2361e-01, -2.6580e-01,\n",
              "          -1.1579e-01,  5.6058e-02,  8.7259e-02, -5.1874e-02,  9.4426e-02,\n",
              "           3.2723e-02, -2.1868e-01,  6.9692e-02, -1.3012e-01, -5.4730e-02,\n",
              "           3.7071e-02, -2.1841e-02,  1.9817e-01,  3.0159e-02,  1.8977e-01,\n",
              "          -2.5901e-02, -8.3778e-02, -3.6552e-02,  1.6424e-01,  1.3704e-01,\n",
              "           1.9279e-01,  2.0585e-01,  2.5869e-01, -1.5531e-01,  3.8388e-02,\n",
              "           7.6753e-02, -3.9664e-02, -8.0089e-02, -3.1283e-01, -1.0247e-01,\n",
              "           5.5398e-02, -1.0737e-01,  4.7428e-02, -8.3824e-04, -6.8306e-02,\n",
              "           4.5089e-02, -2.0373e-01,  1.1894e-01,  1.7323e-01,  3.3122e-02],\n",
              "         [ 1.0063e-02, -2.4432e-01, -8.2352e-02, -4.2619e-02,  1.5426e-01,\n",
              "          -1.7599e-01, -1.4066e-01, -2.8647e-01,  2.3371e-01,  1.7859e-01,\n",
              "           1.0010e-01, -2.0468e-02, -3.8850e-02,  1.0239e-01, -8.6147e-02,\n",
              "           8.7044e-02,  4.2849e-03,  1.1118e-01,  9.8439e-02, -9.9536e-02,\n",
              "          -1.8588e-01,  4.4463e-02, -1.4891e-01, -4.8035e-02, -6.6093e-02,\n",
              "          -6.9886e-02,  2.0087e-01, -2.1600e-01,  5.0131e-02, -9.0902e-02,\n",
              "          -1.1589e-01, -8.9693e-02,  2.0228e-02, -5.1450e-03,  1.3262e-01,\n",
              "          -2.2640e-01, -4.4001e-02,  4.6936e-02, -8.2442e-02,  1.3596e-01,\n",
              "          -6.8198e-02,  1.9294e-02, -2.0350e-01, -1.3660e-02,  1.1530e-01,\n",
              "           1.1545e-01,  1.4625e-01, -4.5109e-02,  1.8060e-02,  8.8223e-02,\n",
              "          -1.3948e-01, -5.3227e-02, -2.0518e-01, -1.5861e-01,  2.2160e-01,\n",
              "          -4.9920e-02, -1.5238e-01,  4.3594e-02,  1.5970e-01, -9.3930e-03,\n",
              "          -5.5266e-02, -5.8060e-02, -4.6610e-02,  2.0426e-03,  1.3895e-01,\n",
              "          -2.2948e-02,  1.0480e-02,  2.6067e-02,  2.4404e-02,  9.0321e-02,\n",
              "           9.4898e-02,  3.3823e-01, -1.0846e-01, -1.1128e-01,  2.7361e-01,\n",
              "           7.4642e-02,  1.4613e-01, -1.2200e-01,  2.5525e-02,  1.6854e-01,\n",
              "          -2.0106e-02,  1.8098e-01,  1.9292e-01,  1.4554e-01, -3.6229e-02,\n",
              "          -4.7495e-02,  2.2238e-01,  1.1425e-01, -3.0988e-02,  2.3775e-01,\n",
              "           3.3616e-02, -2.6470e-02, -2.4326e-01,  1.0893e-01, -2.0466e-01,\n",
              "           8.5760e-02, -2.2108e-01,  1.4294e-01, -1.3349e-01,  9.5851e-03],\n",
              "         [-1.7398e-01,  7.9283e-02,  2.1030e-01, -2.3873e-02,  1.1602e-01,\n",
              "          -2.8882e-02, -4.3189e-04,  8.2607e-02,  1.2641e-01, -1.7740e-01,\n",
              "           1.1546e-01,  1.9201e-01,  3.8515e-02, -1.3486e-02,  9.9661e-02,\n",
              "          -3.8758e-02,  4.7924e-02, -1.5105e-01, -3.8002e-02, -1.7835e-01,\n",
              "          -2.4138e-01, -2.8531e-02, -1.6892e-01,  9.2919e-02, -3.6157e-02,\n",
              "          -8.5864e-02,  6.6378e-03,  6.7041e-02,  3.5022e-01, -3.0430e-01,\n",
              "          -3.6488e-02,  5.4766e-02, -1.8600e-02, -3.1060e-01, -1.5235e-01,\n",
              "          -1.9021e-02,  9.0350e-02,  2.6150e-01, -7.7789e-02,  2.1629e-02,\n",
              "          -1.0928e-01,  1.5601e-01, -1.0421e-01,  1.4300e-01, -6.0026e-02,\n",
              "          -2.6528e-02,  1.2581e-01,  1.3345e-01,  8.6804e-02, -3.7557e-02,\n",
              "          -6.8448e-02, -1.2753e-01, -2.1983e-01,  1.2050e-01, -2.5834e-02,\n",
              "          -6.6616e-02,  7.1088e-02,  3.1864e-01,  6.1444e-02, -3.8838e-01,\n",
              "           7.5030e-02, -1.4105e-01,  3.3396e-03, -9.8624e-02, -5.6369e-02,\n",
              "          -1.7539e-01,  2.6227e-02, -8.2585e-02,  1.9372e-02, -3.8394e-02,\n",
              "           2.0006e-01,  1.5698e-02,  3.5434e-01, -1.5449e-01, -5.6875e-02,\n",
              "           1.8465e-01,  8.3103e-02,  1.5200e-01,  5.7329e-02, -1.2072e-01,\n",
              "          -5.6637e-02,  1.9468e-01, -1.5228e-01, -1.8171e-01, -1.8121e-01,\n",
              "          -4.8243e-02, -1.1454e-01,  2.5987e-03, -2.0717e-03,  4.9063e-02,\n",
              "          -1.2578e-01,  1.4384e-01,  1.6458e-01,  7.0920e-02, -1.3784e-01,\n",
              "           6.1955e-02, -1.4224e-01,  1.5321e-02, -2.1842e-01,  1.2143e-01],\n",
              "         [ 2.7451e-01,  2.4649e-01,  5.0632e-02, -2.6852e-02,  5.0545e-02,\n",
              "          -5.3202e-03,  2.9325e-01, -9.0277e-02,  1.9171e-04, -2.7378e-01,\n",
              "          -1.3000e-01, -1.6460e-01, -5.3560e-02, -5.1785e-02,  2.7238e-01,\n",
              "           1.9565e-01,  1.3149e-02, -2.8579e-01, -7.4477e-02, -1.9561e-02,\n",
              "          -2.6279e-01, -2.6105e-03, -1.1790e-01,  3.0107e-01,  1.4674e-01,\n",
              "           1.5579e-01,  1.3042e-01,  2.7919e-01, -7.4866e-02,  7.3922e-02,\n",
              "          -3.0501e-01, -1.5504e-01,  3.8640e-02,  1.1359e-01,  7.8694e-02,\n",
              "          -1.3655e-01,  1.5313e-01,  6.3921e-02, -2.7277e-02,  2.6159e-01,\n",
              "           2.4722e-02, -1.0627e-01, -1.4261e-01,  4.5596e-02, -6.2824e-02,\n",
              "          -5.5784e-02, -6.1185e-02,  7.8910e-02,  6.5673e-04, -7.9627e-03,\n",
              "          -6.0903e-02,  1.0794e-01, -6.2621e-02,  9.0056e-02,  1.1954e-01,\n",
              "           1.9959e-01, -4.6271e-04,  1.9936e-01,  1.6880e-01,  5.7076e-02,\n",
              "           1.9566e-02, -1.7497e-01, -1.1664e-02, -4.1190e-02,  3.6648e-02,\n",
              "           4.7510e-02,  2.3995e-01, -3.5869e-02, -2.5448e-02,  1.8485e-01,\n",
              "          -5.1281e-02, -5.8045e-03, -6.8962e-02,  9.6261e-03,  5.0771e-02,\n",
              "           2.4389e-01,  2.8601e-03, -3.2393e-01, -1.8974e-04, -8.2223e-02,\n",
              "          -7.7345e-02,  1.6520e-01, -1.5840e-01, -4.8553e-02, -1.2963e-01,\n",
              "          -1.5682e-01, -5.5318e-02, -9.3420e-02,  6.1472e-02,  6.7372e-02,\n",
              "          -5.5369e-02, -6.4763e-02, -4.8640e-02,  6.1670e-02, -1.6493e-02,\n",
              "          -6.5894e-02,  7.4160e-02, -1.5978e-01,  7.0131e-02,  2.5629e-01],\n",
              "         [-2.0773e-01,  3.9407e-03,  9.4820e-02,  7.4423e-02, -5.5282e-02,\n",
              "          -6.7353e-02,  1.1834e-01, -9.0073e-02,  1.6369e-01,  3.0034e-01,\n",
              "          -7.7386e-02, -5.5964e-02, -1.2236e-01, -1.2183e-01,  8.3792e-02,\n",
              "          -1.0302e-01, -6.5895e-03,  1.9711e-01, -1.6019e-01,  2.2167e-01,\n",
              "           4.0291e-02, -6.5159e-02,  1.0869e-01, -2.8194e-02,  1.1536e-01,\n",
              "          -6.5542e-02,  1.5582e-01,  1.9782e-01,  3.5040e-01,  1.3014e-01,\n",
              "           1.1344e-01,  3.8200e-02, -1.4130e-01,  1.8346e-01, -1.9831e-01,\n",
              "           3.1685e-01, -3.5993e-02,  9.2693e-02, -9.1837e-03, -2.8235e-01,\n",
              "           2.7252e-02,  8.2869e-02,  3.1370e-02, -6.1258e-02, -4.1147e-02,\n",
              "           3.9016e-01, -1.3977e-01, -1.3124e-01,  1.2125e-01, -2.4014e-02,\n",
              "          -1.4823e-01,  5.5754e-03, -1.6158e-01,  3.6710e-02,  5.5809e-02,\n",
              "           1.5771e-02, -2.1289e-03,  2.9279e-01,  7.7746e-02,  4.3695e-03,\n",
              "           9.5580e-02,  1.1138e-01, -3.0684e-02, -6.7643e-02,  6.2178e-02,\n",
              "          -1.1814e-01, -4.6579e-02, -1.0800e-01,  1.6420e-01, -2.0501e-01,\n",
              "          -1.0926e-02,  1.4735e-01,  1.8250e-02, -2.4509e-02, -4.9866e-02,\n",
              "          -2.4093e-01, -1.0086e-02,  1.9974e-02,  3.1636e-04,  5.6784e-03,\n",
              "           1.4222e-01, -1.8943e-01, -8.9155e-02, -4.4091e-02, -5.4858e-02,\n",
              "          -1.0081e-02, -3.9005e-01,  3.7525e-02, -3.9490e-02, -9.4844e-02,\n",
              "           4.7506e-02, -1.1570e-01, -1.2110e-02, -5.3758e-02, -7.9044e-02,\n",
              "           1.3881e-01,  3.6117e-01,  1.6673e-02,  4.0618e-02, -2.3386e-03],\n",
              "         [ 3.6424e-01,  4.4377e-02,  5.3040e-02, -6.5709e-02,  8.5287e-02,\n",
              "          -1.5874e-01, -8.3857e-02,  6.5687e-02, -4.3784e-02,  3.1877e-02,\n",
              "           5.7969e-02, -2.1442e-02,  2.3747e-02, -1.0730e-01,  8.3264e-02,\n",
              "          -4.7936e-02,  2.6768e-01, -1.0925e-01,  3.0683e-01,  1.5962e-01,\n",
              "          -7.8649e-02, -1.7914e-01, -7.3019e-02, -1.2686e-01,  1.4654e-01,\n",
              "           2.0428e-01,  1.9995e-01, -6.5742e-02,  3.8237e-01,  1.6860e-02,\n",
              "           1.5329e-01,  9.2693e-02,  2.4072e-02, -9.4571e-02, -7.7835e-02,\n",
              "           1.6539e-01, -2.0007e-01,  2.2457e-01, -3.7397e-02, -1.1028e-01,\n",
              "          -5.5852e-02,  2.8224e-02,  2.4533e-01,  1.1102e-01,  1.2359e-01,\n",
              "          -6.7794e-02, -7.3462e-02,  1.5486e-01, -5.8144e-02, -4.4422e-02,\n",
              "           1.1212e-02, -8.0853e-02, -7.8787e-02,  4.4068e-02, -2.9529e-02,\n",
              "          -4.4723e-02, -2.4168e-01,  1.9264e-02,  1.0525e-01,  4.0739e-02,\n",
              "          -2.4201e-02,  3.8205e-02, -1.5548e-01,  4.1910e-01, -7.1644e-02,\n",
              "          -2.0876e-02, -1.2524e-01,  3.2159e-02,  1.4159e-01, -1.0079e-01,\n",
              "          -5.8867e-02,  1.0300e-01, -1.7364e-01, -4.1635e-02, -3.0027e-02,\n",
              "           6.6252e-02,  1.6129e-01,  4.4294e-02, -8.7772e-02, -2.4495e-01,\n",
              "          -1.4678e-01, -1.3819e-01,  2.3317e-01, -5.9529e-02, -3.6790e-02,\n",
              "          -5.0070e-02, -1.0630e-01, -5.3679e-02,  1.5208e-02,  1.4188e-01,\n",
              "           2.6940e-02,  1.0461e-01,  6.2491e-03,  8.9315e-02, -5.6601e-02,\n",
              "           1.0299e-01,  2.8466e-01, -3.7435e-02, -1.8977e-01,  1.6880e-01],\n",
              "         [ 3.9708e-02, -1.2400e-01, -3.7985e-02,  2.9633e-02, -1.4772e-01,\n",
              "          -8.8855e-02, -1.3039e-02, -1.8786e-01, -2.7480e-01, -2.1203e-01,\n",
              "          -1.6999e-01, -8.2856e-02,  1.8340e-02,  8.4520e-02, -3.8859e-02,\n",
              "          -1.1158e-01,  4.0001e-02,  9.3123e-02, -8.9384e-03, -9.9046e-02,\n",
              "           8.2425e-02,  2.2286e-01, -5.9622e-02, -8.9334e-02, -1.7588e-02,\n",
              "           9.6571e-02,  4.9735e-02,  5.3846e-02, -3.5683e-02, -7.4770e-02,\n",
              "          -2.6830e-02,  2.0241e-01, -2.7017e-02,  1.8661e-02,  1.6142e-01,\n",
              "          -5.7559e-02, -1.2212e-01, -3.3775e-02, -2.5422e-01,  5.9748e-02,\n",
              "          -5.4375e-02,  1.2781e-01,  3.6185e-02,  1.4520e-01,  1.1127e-01,\n",
              "          -1.3185e-01,  2.2674e-01,  1.2576e-01, -1.1082e-01,  1.5784e-01,\n",
              "          -1.0088e-01,  1.5225e-02,  1.3467e-01,  2.2022e-01, -9.8630e-02,\n",
              "           8.2951e-02, -2.9925e-02, -2.3348e-03,  8.6908e-02, -1.6236e-01,\n",
              "          -5.6083e-02,  1.5133e-01, -1.1971e-01,  1.8502e-01, -9.5044e-02,\n",
              "          -7.4807e-02, -5.8227e-02, -1.9328e-01, -1.1521e-01, -2.3751e-02,\n",
              "          -8.0373e-02,  1.4202e-01, -8.1489e-02,  1.4370e-01, -2.1077e-01,\n",
              "           1.7597e-02,  3.0086e-02, -6.1673e-03, -5.2854e-02,  1.9052e-01,\n",
              "          -1.4841e-01, -5.5769e-02,  2.7342e-02,  8.8113e-02,  1.3901e-01,\n",
              "          -4.6700e-02,  2.7700e-02,  7.3020e-02, -5.5705e-02,  1.3758e-01,\n",
              "           1.6818e-02, -5.4806e-02,  2.1179e-01, -1.0249e-01,  1.1149e-01,\n",
              "           8.4022e-02,  1.2490e-01, -7.0799e-03, -1.0952e-01,  8.1330e-02],\n",
              "         [-2.2830e-02,  7.4084e-03, -1.3348e-01,  5.4051e-02,  1.2649e-01,\n",
              "          -8.5319e-02,  2.5572e-01, -1.2209e-01,  9.3398e-02,  1.0452e-01,\n",
              "          -5.8953e-02, -1.9870e-01, -2.5647e-01,  3.9410e-03,  1.1984e-02,\n",
              "          -1.0118e-01, -1.8732e-01, -2.6966e-03,  1.8743e-02, -1.3154e-02,\n",
              "          -1.1248e-01,  1.5649e-01, -1.2478e-01,  1.8664e-01,  5.3675e-02,\n",
              "           9.4663e-02,  3.5376e-02,  6.3471e-03, -5.2073e-02, -1.6439e-01,\n",
              "          -5.5439e-02,  1.7622e-02,  1.4912e-01,  1.1628e-01, -3.6137e-01,\n",
              "          -2.3882e-01,  1.9857e-01, -5.8942e-02, -1.6397e-01, -4.4766e-02,\n",
              "           1.2589e-01,  3.6504e-02, -6.9059e-02, -1.4464e-01, -8.1755e-03,\n",
              "          -1.4229e-02, -2.0544e-01, -6.1270e-03, -2.4404e-01, -3.3397e-01,\n",
              "           1.7852e-02,  1.5680e-01, -7.9393e-02, -4.6690e-02,  1.3431e-01,\n",
              "          -8.0654e-02, -1.8587e-01,  6.1460e-02,  1.1687e-02,  2.0368e-01,\n",
              "          -1.1093e-01, -9.4348e-02,  1.5027e-02,  1.0846e-03, -2.1480e-02,\n",
              "          -8.5222e-02, -1.1816e-01, -3.9629e-02,  2.2324e-01,  1.3290e-01,\n",
              "          -1.9540e-01,  4.4734e-02,  2.3351e-01, -5.9558e-02,  2.9046e-01,\n",
              "          -2.2647e-01,  1.6332e-02, -1.2010e-02, -7.1234e-03, -1.3395e-01,\n",
              "          -7.7442e-02, -2.2681e-01,  1.8519e-01, -2.2166e-01, -2.2450e-01,\n",
              "           9.1564e-02, -2.2177e-01,  2.5023e-01,  5.3867e-02, -1.2584e-01,\n",
              "           2.3580e-01,  7.0751e-02, -1.6408e-01, -8.4852e-02, -3.2305e-02,\n",
              "          -9.9124e-02, -9.4603e-02,  1.3415e-02,  2.4636e-01,  6.4905e-02],\n",
              "         [-2.1530e-01,  6.5725e-03, -1.3415e-01, -7.0508e-02, -3.2335e-02,\n",
              "          -1.8309e-01, -2.1461e-01,  7.1168e-02, -5.2572e-02, -1.4041e-01,\n",
              "           2.4548e-02,  1.1619e-01,  1.1891e-01,  1.5826e-01, -1.1187e-01,\n",
              "          -4.5649e-02, -1.6436e-01,  2.4947e-01,  5.3577e-02,  1.3985e-01,\n",
              "           2.4823e-01, -1.3058e-01, -1.3044e-01,  1.9461e-01,  5.6295e-02,\n",
              "          -1.4436e-01,  1.5125e-02,  8.3211e-02,  4.8440e-02, -1.3524e-01,\n",
              "          -1.9873e-01,  1.1512e-01,  1.1423e-01,  1.4764e-01,  6.5260e-02,\n",
              "          -1.1557e-01,  1.2850e-02, -7.8985e-02, -1.5643e-01,  6.7499e-03,\n",
              "          -2.4367e-02, -6.8194e-02,  1.2308e-01,  2.3179e-01, -1.5774e-01,\n",
              "          -8.9636e-02, -6.1700e-02,  3.6486e-02, -4.7339e-02,  1.2697e-01,\n",
              "          -1.3511e-01, -4.6344e-04,  2.1558e-01,  3.5488e-02,  2.1645e-03,\n",
              "           1.5649e-01,  2.3459e-02,  2.2886e-01,  3.1075e-02, -1.2457e-01,\n",
              "           2.7131e-01,  1.2157e-01,  1.5192e-01,  1.8496e-02, -2.3433e-01,\n",
              "          -1.3007e-01,  9.7868e-02,  2.2595e-01, -2.5853e-02,  9.5901e-02,\n",
              "           1.3739e-01, -3.5675e-02, -2.6975e-01, -1.8588e-01, -1.3943e-01,\n",
              "          -1.5842e-01,  1.5366e-01,  1.0504e-01,  9.0978e-04,  1.2828e-01,\n",
              "          -1.8482e-01,  2.6341e-02, -9.7015e-02, -3.9626e-03,  2.3734e-01,\n",
              "           1.0678e-01, -2.6171e-02,  3.7656e-02,  1.1495e-01,  3.6896e-02,\n",
              "          -6.7542e-02,  1.0858e-01,  7.4761e-02,  9.0330e-02, -5.5755e-02,\n",
              "          -8.4780e-02,  1.7755e-01, -1.1665e-01,  1.0071e-01,  1.3326e-01],\n",
              "         [ 3.2832e-01, -1.7673e-01, -2.4576e-02, -6.4374e-03,  1.3014e-02,\n",
              "           5.1981e-02, -9.0512e-02, -9.6212e-02, -1.0563e-01, -9.4959e-02,\n",
              "          -1.9906e-01,  8.2708e-03, -2.9039e-01,  1.7309e-01,  1.4931e-01,\n",
              "           1.5553e-01,  2.3372e-03,  3.9059e-02, -1.4321e-01,  1.4845e-01,\n",
              "           1.1985e-01, -1.8442e-01, -1.6106e-01,  3.1861e-02,  1.4373e-01,\n",
              "           1.8010e-01, -8.0483e-02, -1.4031e-01,  2.3876e-04, -5.6178e-03,\n",
              "          -1.2240e-01,  1.2810e-01, -7.7546e-02, -2.2632e-01,  2.3602e-01,\n",
              "          -3.2755e-03, -4.1207e-02,  5.5855e-02, -9.9519e-02, -1.7181e-02,\n",
              "          -1.9067e-03,  2.3657e-02, -6.3623e-02, -1.8037e-02,  9.6122e-02,\n",
              "           1.7371e-01,  4.7021e-02, -6.3218e-03,  1.6544e-01, -1.5062e-01,\n",
              "           2.8390e-02,  2.7335e-01,  6.9270e-02, -1.2898e-01,  1.5156e-02,\n",
              "           1.5636e-01,  1.4847e-01,  5.4999e-02,  3.9656e-01,  1.4851e-01,\n",
              "          -2.0086e-01,  1.2406e-01, -2.4567e-02,  1.7365e-02, -1.7280e-01,\n",
              "           1.5153e-01, -5.0543e-02, -2.5608e-02, -2.8888e-01, -1.1401e-01,\n",
              "          -2.4053e-01, -2.6670e-02, -8.8216e-02, -1.5126e-01,  4.4174e-02,\n",
              "          -5.3436e-02, -1.0179e-01, -1.9839e-01,  3.4162e-02,  3.0028e-01,\n",
              "          -1.5082e-01, -7.1767e-02,  1.2770e-01,  1.7891e-01, -4.5194e-02,\n",
              "           2.4826e-02,  7.4704e-02, -4.7356e-03, -5.5979e-02, -1.1754e-01,\n",
              "          -4.8297e-02,  5.5198e-02,  1.4579e-01,  1.1682e-01, -2.9331e-01,\n",
              "          -8.8393e-02, -7.4359e-02,  1.7714e-01, -6.5094e-03, -9.8495e-02]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([ 0.3866,  0.6238, -1.6625, -0.0961,  0.4846,  1.5575,  0.9681, -1.0526,\n",
              "         -0.3803,  0.4931], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEH54l190_D4",
        "colab_type": "code",
        "outputId": "9e5938ff-53b8-4bcf-9a5e-414f30176db2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "print(list(net.named_modules()))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('', LeNetTrash(\n",
            "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
            "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
            ")), ('fc1', Linear(in_features=784, out_features=300, bias=True)), ('fc2', Linear(in_features=300, out_features=100, bias=True)), ('fc3', Linear(in_features=100, out_features=10, bias=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2hnO309DNyX",
        "colab_type": "code",
        "outputId": "57d42e23-74c5-4f0f-dd25-7d9e262cf21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_one_epoch(net, train_loader, optimizer, criterion)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0746472030878067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kCpS0_LNYNP",
        "colab_type": "code",
        "outputId": "a911436c-822d-4807-e0bf-905fe456deff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "prune.l1_unstructured(net.fc1, 'weight', 0.1)\n",
        "prune.l1_unstructured(net.fc2, 'weight', 0.1)\n",
        "prune.l1_unstructured(net.fc3, 'weight', 0.1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=100, out_features=10, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1RoERwdRsVv",
        "colab_type": "code",
        "outputId": "63edb6a0-c4bd-44c2-941c-d0ebfedd8860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(net.state_dict().keys())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['fc1.bias', 'fc1.weight_orig', 'fc1.weight_mask', 'fc2.bias', 'fc2.weight_orig', 'fc2.weight_mask', 'fc3.bias', 'fc3.weight_orig', 'fc3.weight_mask'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RglgkAqnVcO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "58a499d4-3ce6-43c0-cbb1-4e5740372b03"
      },
      "source": [
        "for parameter in net.fc1.named_parameters():\n",
        "    print(parameter[0])\n",
        "\n",
        "for parameter in net.fc1.parameters():\n",
        "    print(parameter.shape)\n",
        "\n",
        "print(net.fc1.weight.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bias\n",
            "weight_orig\n",
            "torch.Size([300])\n",
            "torch.Size([300, 784])\n",
            "torch.Size([300, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhRVdyUSRy82",
        "colab_type": "code",
        "outputId": "ad7737fe-1ebe-4b7b-8c5e-983b7b64c225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "print(net.fc1.weight_orig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.2672e-39,  1.0505e-37,  4.4345e-39,  ...,  1.4049e-39,\n",
            "          1.1837e-37, -4.2345e-39],\n",
            "        [ 3.0337e-37,  1.5924e-37, -5.6929e-39,  ..., -3.0686e-39,\n",
            "         -1.0979e-37, -4.8788e-39],\n",
            "        [-5.9204e-39,  2.1624e-39,  6.6162e-39,  ..., -1.0876e-39,\n",
            "         -1.8000e-39,  1.2207e-37],\n",
            "        ...,\n",
            "        [ 4.0793e-39, -3.6856e-40,  4.0646e-38,  ..., -3.0056e-39,\n",
            "         -1.2159e-37,  4.5388e-39],\n",
            "        [ 1.3105e-38, -3.9764e-39,  4.1318e-39,  ..., -4.8299e-39,\n",
            "         -1.6280e-37,  2.9855e-40],\n",
            "        [ 9.4934e-40,  1.7330e-39, -2.0795e-38,  ..., -2.8807e-39,\n",
            "         -3.9555e-39,  2.9408e-39]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sNQ1tcUR7zV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight_orig_clone1 = net.fc1.weight_orig.detach().clone()\n",
        "weight_clone1 = net.fc1.weight.detach().clone()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7AlmxPTSJEb",
        "colab_type": "code",
        "outputId": "dd0994a9-78d1-4886-ab13-835a02cc4a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "print(weight_orig_clone1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.2672e-39,  1.0505e-37,  4.4345e-39,  ...,  1.4049e-39,\n",
            "          1.1837e-37, -4.2345e-39],\n",
            "        [ 3.0337e-37,  1.5924e-37, -5.6929e-39,  ..., -3.0686e-39,\n",
            "         -1.0979e-37, -4.8788e-39],\n",
            "        [-5.9204e-39,  2.1624e-39,  6.6162e-39,  ..., -1.0876e-39,\n",
            "         -1.8000e-39,  1.2207e-37],\n",
            "        ...,\n",
            "        [ 4.0793e-39, -3.6856e-40,  4.0646e-38,  ..., -3.0056e-39,\n",
            "         -1.2159e-37,  4.5388e-39],\n",
            "        [ 1.3105e-38, -3.9764e-39,  4.1318e-39,  ..., -4.8299e-39,\n",
            "         -1.6280e-37,  2.9855e-40],\n",
            "        [ 9.4934e-40,  1.7330e-39, -2.0795e-38,  ..., -2.8807e-39,\n",
            "         -3.9555e-39,  2.9408e-39]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAf7un34SMZ1",
        "colab_type": "code",
        "outputId": "5819d436-ff3e-44db-9138-b66c8c1471b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "print(weight_clone1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000e+00,  1.0505e-37,  4.4345e-39,  ...,  0.0000e+00,\n",
            "          1.1837e-37, -4.2345e-39],\n",
            "        [ 0.0000e+00,  0.0000e+00, -5.6929e-39,  ..., -0.0000e+00,\n",
            "         -1.0979e-37, -4.8788e-39],\n",
            "        [-5.9204e-39,  0.0000e+00,  6.6162e-39,  ..., -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [ 4.0793e-39, -0.0000e+00,  4.0646e-38,  ..., -0.0000e+00,\n",
            "         -0.0000e+00,  0.0000e+00],\n",
            "        [ 0.0000e+00, -3.9764e-39,  4.1318e-39,  ..., -4.8299e-39,\n",
            "         -1.6280e-37,  0.0000e+00],\n",
            "        [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "         -3.9555e-39,  0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFbyEsdgH5X-",
        "colab_type": "code",
        "outputId": "c7f3aca2-5c4c-4aaa-b532-9c9598e34eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_one_epoch(net, train_loader, optimizer, criterion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015482593327760696"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jagjB52oWxA9",
        "colab_type": "code",
        "outputId": "2b67834c-e550-40c5-e955-d969e6c59e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "print(weight_orig_clone1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.2672e-39,  1.0505e-37,  4.4345e-39,  ...,  1.4049e-39,\n",
            "          1.1837e-37, -4.2345e-39],\n",
            "        [ 3.0337e-37,  1.5924e-37, -5.6929e-39,  ..., -3.0686e-39,\n",
            "         -1.0979e-37, -4.8788e-39],\n",
            "        [-5.9204e-39,  2.1624e-39,  6.6162e-39,  ..., -1.0876e-39,\n",
            "         -1.8000e-39,  1.2207e-37],\n",
            "        ...,\n",
            "        [ 4.0793e-39, -3.6856e-40,  4.0646e-38,  ..., -3.0056e-39,\n",
            "         -1.2159e-37,  4.5388e-39],\n",
            "        [ 1.3105e-38, -3.9764e-39,  4.1318e-39,  ..., -4.8299e-39,\n",
            "         -1.6280e-37,  2.9855e-40],\n",
            "        [ 9.4934e-40,  1.7330e-39, -2.0795e-38,  ..., -2.8807e-39,\n",
            "         -3.9555e-39,  2.9408e-39]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQe-E1EZW3zr",
        "colab_type": "code",
        "outputId": "5d32d160-f1fc-4720-cfdd-4138d58ed513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "print(net.fc1.weight_orig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.2672e-39, -1.7521e-37,  4.4345e-39,  ...,  1.4049e-39,\n",
            "          1.1837e-37, -4.2345e-39],\n",
            "        [ 3.0337e-37,  1.9106e-38, -5.6929e-39,  ..., -3.0686e-39,\n",
            "          1.7047e-37, -4.8788e-39],\n",
            "        [-5.9204e-39,  2.1624e-39,  6.6162e-39,  ..., -1.0876e-39,\n",
            "         -1.8000e-39, -1.8060e-38],\n",
            "        ...,\n",
            "        [ 4.0793e-39, -3.6856e-40,  4.0646e-38,  ..., -3.0056e-39,\n",
            "          1.8539e-38,  4.5388e-39],\n",
            "        [ 1.3105e-38, -3.9764e-39,  4.1318e-39,  ..., -4.8299e-39,\n",
            "         -1.6280e-37,  2.9855e-40],\n",
            "        [ 9.4934e-40,  1.7330e-39,  1.1934e-37,  ..., -2.8807e-39,\n",
            "         -3.9555e-39,  2.9408e-39]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NYu3akGICcg",
        "colab_type": "code",
        "outputId": "eafbfc19-95a4-40fa-af49-62e9bedf5299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        }
      },
      "source": [
        "print(weight_orig_clone1.eq(net.fc1.weight_orig))\n",
        "print(weight_clone1.eq(net.fc1.weight))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ True, False,  True,  ...,  True,  True,  True],\n",
            "        [ True, False,  True,  ...,  True, False,  True],\n",
            "        [ True,  True,  True,  ...,  True,  True, False],\n",
            "        ...,\n",
            "        [ True,  True,  True,  ...,  True, False,  True],\n",
            "        [ True,  True,  True,  ...,  True,  True,  True],\n",
            "        [ True,  True, False,  ...,  True,  True,  True]])\n",
            "tensor([[ True, False,  True,  ...,  True,  True,  True],\n",
            "        [ True,  True,  True,  ...,  True, False,  True],\n",
            "        [ True,  True,  True,  ...,  True,  True,  True],\n",
            "        ...,\n",
            "        [ True,  True, False,  ...,  True,  True,  True],\n",
            "        [ True,  True,  True,  ...,  True, False,  True],\n",
            "        [ True,  True,  True,  ...,  True,  True,  True]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssnpakPpSmwj",
        "colab_type": "code",
        "outputId": "4bd5081e-7115-458c-f0bc-33aa557b8c7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "optimizer.state_dict().keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['state', 'param_groups'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sGv8V4fnRlW",
        "colab_type": "code",
        "outputId": "0f757a6f-c797-47e5-b3ce-c2916332c7a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Initialise loss function.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Testing training a few epochs, saving the best model then loading it.\n",
        "pruning_iterations = 5\n",
        "epochs = 20\n",
        "\n",
        "# Frequency for getting train/validation losses + (saving the best model).\n",
        "test_freq = 2\n",
        "\n",
        "# Experiments results + logs will be saved in the \"experiments\" folder.\n",
        "base_dir = \"pruning_experiments\"\n",
        "experiment_name = \"FC_test_run\"\n",
        "best_model_filename = \"best_model\"\n",
        "\n",
        "# Initialise a SummaryWriter in order to use tensorboard + log relevant results.\n",
        "writer = SummaryWriter(experiment_PATH)\n",
        "\n",
        "for pruning_iter in range(pruning_iterations):\n",
        "\n",
        "    experiment_PATH = base_dir + '/' + experiment_name + '/pruning_' + str(pruning_iter)\n",
        "    os.makedirs(experiment_PATH, exist_ok=True)\n",
        "\n",
        "    print('\\n\\nStarting pruning iteration: ' + str(pruning_iter) + '\\n')\n",
        "\n",
        "    if(pruning_iter != 0):\n",
        "\n",
        "\n",
        "    # Initialize optimizer:\n",
        "    optimizer = torch.optim.Adam(net.parameters(), weight_decay=1e-4)\n",
        "\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(epochs):\n",
        "        train_one_epoch(net, train_loader, optimizer, criterion)\n",
        "\n",
        "        if epoch % test_freq == 0:\n",
        "            train_acc, train_loss = calculate_accuracy_and_loss(net, train_loader, criterion)\n",
        "            valid_acc, valid_loss = calculate_accuracy_and_loss(net, valid_loader, criterion)\n",
        "\n",
        "            writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
        "            writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "            writer.add_scalar('Accuracy/valid', valid_acc, epoch)\n",
        "            writer.add_scalar('Loss/valid', valid_loss, epoch)\n",
        "\n",
        "            if(valid_acc > best_accuracy):\n",
        "                best_accuracy = valid_acc\n",
        "                PATH = get_best_model_PATH(experiment_PATH, best_model_filename, 0)\n",
        "                remove_checkpoint(PATH)\n",
        "                save_checkpoint(PATH, epoch, net, optimizer)\n",
        "\n",
        "            print('Epoch: ' + str(epoch) +  ', Train loss: {:.4f}, Train Acc: {:.2f}, Valid loss: {:.4f}, Valid Acc: {:.2f}'.format(train_loss, train_acc, valid_loss, valid_acc))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 0, Train loss: 0.0379, Train Acc: 98.72, Valid loss: 0.0379, Valid Acc: 98.72:   0%|          | 0/10 [00:54<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 0, Train loss: 0.0379, Train Acc: 98.72, Valid loss: 0.0379, Valid Acc: 98.72:  10%|         | 1/10 [00:54<08:12, 54.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 0, Train loss: 0.0379, Train Acc: 98.72, Valid loss: 0.0379, Valid Acc: 98.72:  20%|        | 2/10 [01:17<06:00, 45.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 2, Train loss: 0.0342, Train Acc: 98.86, Valid loss: 0.0342, Valid Acc: 98.86:  20%|        | 2/10 [01:55<06:00, 45.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 2, Train loss: 0.0342, Train Acc: 98.86, Valid loss: 0.0342, Valid Acc: 98.86:  30%|       | 3/10 [01:55<04:59, 42.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 2, Train loss: 0.0342, Train Acc: 98.86, Valid loss: 0.0342, Valid Acc: 98.86:  40%|      | 4/10 [02:14<03:34, 35.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 4, Train loss: 0.0271, Train Acc: 99.13, Valid loss: 0.0272, Valid Acc: 99.13:  40%|      | 4/10 [02:48<03:34, 35.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 4, Train loss: 0.0271, Train Acc: 99.13, Valid loss: 0.0272, Valid Acc: 99.13:  50%|     | 5/10 [02:48<02:56, 35.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 4, Train loss: 0.0271, Train Acc: 99.13, Valid loss: 0.0272, Valid Acc: 99.13:  60%|    | 6/10 [03:07<02:02, 30.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 6, Train loss: 0.0255, Train Acc: 99.16, Valid loss: 0.0255, Valid Acc: 99.16:  60%|    | 6/10 [03:47<02:02, 30.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 6, Train loss: 0.0255, Train Acc: 99.16, Valid loss: 0.0255, Valid Acc: 99.16:  70%|   | 7/10 [03:47<01:39, 33.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 6, Train loss: 0.0255, Train Acc: 99.16, Valid loss: 0.0255, Valid Acc: 99.16:  80%|  | 8/10 [04:09<00:59, 29.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 8, Train loss: 0.0146, Train Acc: 99.56, Valid loss: 0.0146, Valid Acc: 99.56:  80%|  | 8/10 [04:49<00:59, 29.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 8, Train loss: 0.0146, Train Acc: 99.56, Valid loss: 0.0146, Valid Acc: 99.56:  90%| | 9/10 [04:49<00:32, 32.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 8, Train loss: 0.0146, Train Acc: 99.56, Valid loss: 0.0146, Valid Acc: 99.56: 100%|| 10/10 [05:09<00:00, 29.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M89htq977Ad",
        "colab_type": "code",
        "outputId": "b14e8529-a149-41bb-c44c-02218d6b79de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(experiment_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "experiments/FC_test_run\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tERUHTwNyv9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start a tensorboard session.\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir experiments/FC_test_run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIbdArmWQTyc",
        "colab_type": "code",
        "outputId": "d8c5dd96-85f4-4a83-e1bf-0ad28d4bcc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "for prune_iteration in range(nr_prune_iterations):\n",
        "    if(prune_iteration != 0):\n",
        "        # Need to save original parameters of the model.\n",
        "        # Prune parameters.\n",
        "        # Re-initialise parameters.\n",
        "        # Re-initialize optimizer (add only the parameters that learn).\n",
        "        # Something to do with the device?\n",
        "        pass\n",
        "    \n",
        "    for train_iteration in range(train_iterations):\n",
        "        # If train_iteration... record the accuracy/loss.\n",
        "        # If it's the best accuracy, save the model + optimiser parameters.\n",
        "        # Train the model.\n",
        "        # Need a train function (for one iteration?) + test function for evaluating...\n",
        "    # Make figures, save them.\n",
        "\n",
        "# TODO: use pruningmethod for weight magnitudes then for gradients.\n",
        "# Apparently, you need to take into account the device you are working with\n",
        "# (CPU vs GPU) when doing this shit."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-2c00deafc4c3>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAYTm61A0sXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nr_prune_iterations = 10\n",
        "epochs = 100\n",
        "\n",
        "best_loss = np.inf\n",
        "train_losses = np.zeros((epochs, ))\n",
        "test_losses = np.zeros((epochs, ))\n",
        "for epoch in range(epochs):\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ixSOzx5ft1g",
        "colab_type": "code",
        "outputId": "8c038912-a4f5-4a39-bbc6-1c02e33955b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.407292902469635"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khR48kiSdl54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_test_loss(model, test_loader, optimizer, criterion):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "694R9IUJ2aao",
        "colab_type": "code",
        "outputId": "f667db44-fd4e-4979-cd2c-f0ede0fb98a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "net.state_dict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.state_dict of LeNetTrash(\n",
              "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
              "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rZ01PgeVvbh",
        "colab_type": "code",
        "outputId": "508d61a9-3d3e-4185-ba30-0a4c985888b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "print(net.fc1.weight.data.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7.3078976e-40 -3.5359847e-39 -5.1571147e-40 ... -1.5360235e-39\n",
            "   5.1942575e-39 -2.8576764e-39]\n",
            " [-4.2151913e-39 -5.1506715e-39 -2.7939061e-39 ... -2.4624598e-39\n",
            "  -3.9547263e-39  3.9824174e-39]\n",
            " [ 1.9701430e-39 -4.2787303e-39 -4.1677834e-38 ...  1.7528899e-39\n",
            "   7.7572408e-39  5.2655611e-39]\n",
            " ...\n",
            " [ 6.2717579e-39  2.4628928e-39 -7.6535122e-38 ... -2.7414684e-38\n",
            "   1.0152351e-39 -1.1631659e-34]\n",
            " [ 2.4143823e-38  3.6544967e-39 -8.4877349e-39 ...  7.0279462e-40\n",
            "  -5.5321960e-39 -2.6077940e-39]\n",
            " [ 2.4695559e-39  5.0258018e-39 -4.5261940e-42 ...  6.2589556e-40\n",
            "  -5.3935642e-39  2.2270416e-40]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NIl5VrRVyrf",
        "colab_type": "code",
        "outputId": "1e4edc88-6553-4300-8af4-72bb8365a87e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "optimizer."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Optimizer.state_dict of Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    eps: 1e-08\n",
              "    lr: 0.001\n",
              "    weight_decay: 0.0001\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRDBSkAX843Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Pruning Tutorial\n",
        "=====================================\n",
        "**Author**: `Michela Paganini <https://github.com/mickypaganini>`_\n",
        "\n",
        "State-of-the-art deep learning techniques rely on over-parametrized models \n",
        "that are hard to deploy. On the contrary, biological neural networks are \n",
        "known to use efficient sparse connectivity. Identifying optimal  \n",
        "techniques to compress models by reducing the number of parameters in them is \n",
        "important in order to reduce memory, battery, and hardware consumption without \n",
        "sacrificing accuracy, deploy lightweight models on device, and guarantee \n",
        "privacy with private on-device computation. On the research front, pruning is \n",
        "used to investigate the differences in learning dynamics between \n",
        "over-parametrized and under-parametrized networks, to study the role of lucky \n",
        "sparse subnetworks and initializations\n",
        "(\"`lottery tickets <https://arxiv.org/abs/1803.03635>`_\") as a destructive \n",
        "neural architecture search technique, and more.\n",
        "\n",
        "In this tutorial, you will learn how to use ``torch.nn.utils.prune`` to \n",
        "sparsify your neural networks, and how to extend it to implement your \n",
        "own custom pruning technique.\n",
        "\n",
        "Requirements\n",
        "------------\n",
        "``\"torch>=1.4.0a0+8e8a5e0\"``\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.utils.prune as prune\n",
        "import torch.nn.functional as F\n",
        "\n",
        "######################################################################\n",
        "# Create a model\n",
        "# --------------\n",
        "#\n",
        "# In this tutorial, we use the `LeNet \n",
        "# <http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf>`_ architecture from \n",
        "# LeCun et al., 1998.\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square conv kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5x5 image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, int(x.nelement() / x.shape[0]))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = LeNet().to(device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWGZDNDA89s8",
        "colab_type": "code",
        "outputId": "e8b9c1cd-8682-462e-ed59-ea9d1ad23fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "######################################################################\n",
        "# Inspect a Module\n",
        "# ----------------\n",
        "# \n",
        "# Let's inspect the (unpruned) ``conv1`` layer in our LeNet model. It will contain two \n",
        "# parameters ``weight`` and ``bias``, and no buffers, for now.\n",
        "module = model.conv1\n",
        "print(list(module.named_parameters()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[[[ 0.2138,  0.1507,  0.1297],\n",
            "          [-0.0887, -0.3002, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.2232,  0.0195],\n",
            "          [ 0.2123, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.1297,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.1988, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.1998,  0.1009, -0.0759],\n",
            "          [-0.0180,  0.0602, -0.2492],\n",
            "          [ 0.0734, -0.2812, -0.0847]]],\n",
            "\n",
            "\n",
            "        [[[-0.0311,  0.3279, -0.1438],\n",
            "          [-0.2013, -0.1219, -0.0993],\n",
            "          [ 0.1979,  0.0930, -0.0901]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.2402, -0.1435],\n",
            "          [ 0.2260,  0.0478,  0.1106],\n",
            "          [ 0.0376,  0.0913, -0.1595]]]], requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([ 0.2093, -0.2762,  0.2606, -0.2037,  0.1396, -0.3161],\n",
            "       requires_grad=True))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8SYsiod9F2k",
        "colab_type": "code",
        "outputId": "93d4faf2-5ff5-4ad8-f589-a09a4615475f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "######################################################################\n",
        "print(list(module.named_buffers()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbqHP8Tx9Tkj",
        "colab_type": "code",
        "outputId": "f0fc66cd-2bab-489b-a801-cf1a2145b611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "######################################################################\n",
        "# Pruning a Module\n",
        "# ----------------\n",
        "# \n",
        "# To prune a module (in this example, the ``conv1`` layer of our LeNet \n",
        "# architecture), first select a pruning technique among those available in \n",
        "# ``torch.nn.utils.prune`` (or\n",
        "# `implement <#extending-torch-nn-utils-pruning-with-custom-pruning-functions>`_\n",
        "# your own by subclassing \n",
        "# ``BasePruningMethod``). Then, specify the module and the name of the parameter to \n",
        "# prune within that module. Finally, using the adequate keyword arguments \n",
        "# required by the selected pruning technique, specify the pruning parameters.\n",
        "#\n",
        "# In this example, we will prune at random 30% of the connections in \n",
        "# the parameter named ``weight`` in the ``conv1`` layer.\n",
        "# The module is passed as the first argument to the function; ``name`` \n",
        "# identifies the parameter within that module using its string identifier; and \n",
        "# ``amount`` indicates either the percentage of connections to prune (if it \n",
        "# is a float between 0. and 1.), or the absolute number of connections to \n",
        "# prune (if it is a non-negative integer).\n",
        "prune.random_unstructured(module, name=\"weight\", amount=0.3) \n",
        "\n",
        "######################################################################\n",
        "# Pruning acts by removing ``weight`` from the parameters and replacing it with \n",
        "# a new parameter called ``weight_orig`` (i.e. appending ``\"_orig\"`` to the \n",
        "# initial parameter ``name``). ``weight_orig`` stores the unpruned version of \n",
        "# the tensor. The ``bias`` was not pruned, so it will remain intact.\n",
        "print(list(module.named_parameters()))\n",
        "\n",
        "######################################################################\n",
        "# The pruning mask generated by the pruning technique selected above is saved \n",
        "# as a module buffer named ``weight_mask`` (i.e. appending ``\"_mask\"`` to the \n",
        "# initial parameter ``name``).\n",
        "print(list(module.named_buffers()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('bias', Parameter containing:\n",
            "tensor([ 0.2093, -0.2762,  0.2606, -0.2037,  0.1396, -0.3161],\n",
            "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.2138,  0.1507,  0.1297],\n",
            "          [-0.0887, -0.3002, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.2232,  0.0195],\n",
            "          [ 0.2123, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.1297,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.1988, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.1998,  0.1009, -0.0759],\n",
            "          [-0.0180,  0.0602, -0.2492],\n",
            "          [ 0.0734, -0.2812, -0.0847]]],\n",
            "\n",
            "\n",
            "        [[[-0.0311,  0.3279, -0.1438],\n",
            "          [-0.2013, -0.1219, -0.0993],\n",
            "          [ 0.1979,  0.0930, -0.0901]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.2402, -0.1435],\n",
            "          [ 0.2260,  0.0478,  0.1106],\n",
            "          [ 0.0376,  0.0913, -0.1595]]]], requires_grad=True))]\n",
            "[('weight_mask', tensor([[[[0., 0., 1.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0.],\n",
            "          [0., 1., 0.],\n",
            "          [1., 1., 0.]]]]))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjHiiPhu-Y80",
        "colab_type": "code",
        "outputId": "7985a825-5d3e-4808-e1f8-39fc8e587ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "######################################################################\n",
        "# For the forward pass to work without modification, the ``weight`` attribute \n",
        "# needs to exist. The pruning techniques implemented in \n",
        "# ``torch.nn.utils.prune`` compute the pruned version of the weight (by \n",
        "# combining the mask with the original parameter) and store them in the \n",
        "# attribute ``weight``. Note, this is no longer a parameter of the ``module``,\n",
        "# it is now simply an attribute.\n",
        "print(module.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.0000,  0.0000,  0.1297],\n",
            "          [-0.0887, -0.0000, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.0000,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.0000, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.1998,  0.1009, -0.0759],\n",
            "          [-0.0180,  0.0602, -0.2492],\n",
            "          [ 0.0734, -0.0000, -0.0847]]],\n",
            "\n",
            "\n",
            "        [[[-0.0311,  0.3279, -0.0000],\n",
            "          [-0.2013, -0.0000, -0.0993],\n",
            "          [ 0.1979,  0.0930, -0.0901]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.2402, -0.0000],\n",
            "          [ 0.0000,  0.0478,  0.0000],\n",
            "          [ 0.0376,  0.0913, -0.0000]]]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfB-bFpv-3TX",
        "colab_type": "code",
        "outputId": "cb1c16fa-30d8-4932-fbfb-70ecbe561b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "######################################################################\n",
        "# Finally, pruning is applied prior to each forward pass using PyTorch's\n",
        "# ``forward_pre_hooks``. Specifically, when the ``module`` is pruned, as we \n",
        "# have done here, it will acquire a ``forward_pre_hook`` for each parameter \n",
        "# associated with it that gets pruned. In this case, since we have so far \n",
        "# only pruned the original parameter named ``weight``, only one hook will be\n",
        "# present.\n",
        "print(module._forward_pre_hooks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([(28, <torch.nn.utils.prune.RandomUnstructured object at 0x7f8cda9824a8>)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVCMJbUlA7bE",
        "colab_type": "code",
        "outputId": "0d0f5fe6-2e5c-4882-a44e-52677de4dcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "######################################################################\n",
        "# For completeness, we can now prune the ``bias`` too, to see how the \n",
        "# parameters, buffers, hooks, and attributes of the ``module`` change.\n",
        "# Just for the sake of trying out another pruning technique, here we prune the \n",
        "# 3 smallest entries in the bias by L1 norm, as implemented in the \n",
        "# ``l1_unstructured`` pruning function.\n",
        "prune.l1_unstructured(module, name=\"bias\", amount=3)\n",
        "\n",
        "######################################################################\n",
        "# We now expect the named parameters to include both ``weight_orig`` (from \n",
        "# before) and ``bias_orig``. The buffers will include ``weight_mask`` and \n",
        "# ``bias_mask``. The pruned versions of the two tensors will exist as \n",
        "# module attributes, and the module will now have two ``forward_pre_hooks``.\n",
        "print(list(module.named_parameters()))\n",
        "\n",
        "######################################################################\n",
        "print(list(module.named_buffers()))\n",
        "\n",
        "######################################################################\n",
        "print(module.bias)\n",
        "\n",
        "######################################################################\n",
        "print(module._forward_pre_hooks)\n",
        "\n",
        "######################################################################\n",
        "# Iterative Pruning\n",
        "# -----------------\n",
        "# \n",
        "# The same parameter in a module can be pruned multiple times, with the \n",
        "# effect of the various pruning calls being equal to the combination of the\n",
        "# various masks applied in series.\n",
        "# The combination of a new mask with the old mask is handled by the \n",
        "# ``PruningContainer``'s ``compute_mask`` method.\n",
        "#\n",
        "# Say, for example, that we now want to further prune ``module.weight``, this\n",
        "# time using structured pruning along the 0th axis of the tensor (the 0th axis \n",
        "# corresponds to the output channels of the convolutional layer and has \n",
        "# dimensionality 6 for ``conv1``), based on the channels' L2 norm. This can be \n",
        "# achieved using the ``ln_structured`` function, with ``n=2`` and ``dim=0``.\n",
        "prune.ln_structured(module, name=\"weight\", amount=0.5, n=2, dim=0)\n",
        "\n",
        "# As we can verify, this will zero out all the connections corresponding to \n",
        "# 50% (3 out of 6) of the channels, while preserving the action of the \n",
        "# previous mask.\n",
        "print(module.weight)\n",
        "\n",
        "############################################################################\n",
        "# The corresponding hook will now be of type \n",
        "# ``torch.nn.utils.prune.PruningContainer``, and will store the history of \n",
        "# pruning applied to the ``weight`` parameter.\n",
        "for hook in module._forward_pre_hooks.values():\n",
        "    if hook._tensor_name == \"weight\":  # select out the correct hook\n",
        "        break\n",
        "\n",
        "print(list(hook))  # pruning history in the container \n",
        "\n",
        "######################################################################\n",
        "# Serializing a pruned model\n",
        "# --------------------------\n",
        "# All relevant tensors, including the mask buffers and the original parameters\n",
        "# used to compute the pruned tensors are stored in the model's ``state_dict`` \n",
        "# and can therefore be easily serialized and saved, if needed.\n",
        "print(model.state_dict().keys())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.2138,  0.1507,  0.1297],\n",
            "          [-0.0887, -0.3002, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.2232,  0.0195],\n",
            "          [ 0.2123, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.1297,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.1988, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.1998,  0.1009, -0.0759],\n",
            "          [-0.0180,  0.0602, -0.2492],\n",
            "          [ 0.0734, -0.2812, -0.0847]]],\n",
            "\n",
            "\n",
            "        [[[-0.0311,  0.3279, -0.1438],\n",
            "          [-0.2013, -0.1219, -0.0993],\n",
            "          [ 0.1979,  0.0930, -0.0901]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.2402, -0.1435],\n",
            "          [ 0.2260,  0.0478,  0.1106],\n",
            "          [ 0.0376,  0.0913, -0.1595]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.2093, -0.2762,  0.2606, -0.2037,  0.1396, -0.3161],\n",
            "       requires_grad=True))]\n",
            "[('weight_mask', tensor([[[[0., 0., 1.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 0.],\n",
            "          [0., 1., 0.],\n",
            "          [1., 1., 0.]]]])), ('bias_mask', tensor([0., 1., 1., 0., 0., 1.]))]\n",
            "tensor([ 0.0000, -0.2762,  0.2606, -0.0000,  0.0000, -0.3161],\n",
            "       grad_fn=<MulBackward0>)\n",
            "OrderedDict([(28, <torch.nn.utils.prune.RandomUnstructured object at 0x7f8cda9824a8>), (29, <torch.nn.utils.prune.L1Unstructured object at 0x7f8d275cc160>)])\n",
            "tensor([[[[ 0.0000,  0.0000,  0.1297],\n",
            "          [-0.0887, -0.0000, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.0000,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.0000, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]]], grad_fn=<MulBackward0>)\n",
            "[<torch.nn.utils.prune.RandomUnstructured object at 0x7f8cda9824a8>, <torch.nn.utils.prune.LnStructured object at 0x7f8cda982c50>]\n",
            "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNI_f6_TBKGj",
        "colab_type": "code",
        "outputId": "d1e7080c-2e18-41ec-8064-9ceda35a3dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "######################################################################\n",
        "# Remove pruning re-parametrization\n",
        "# ---------------------------------\n",
        "#\n",
        "# To make the pruning permanent, remove the re-parametrization in terms\n",
        "# of ``weight_orig`` and ``weight_mask``, and remove the ``forward_pre_hook``,\n",
        "# we can use the ``remove`` functionality from ``torch.nn.utils.prune``.\n",
        "# Note that this doesn't undo the pruning, as if it never happened. It simply \n",
        "# makes it permanent, instead, by reassigning the parameter ``weight`` to the \n",
        "# model parameters, in its pruned version.\n",
        "\n",
        "######################################################################\n",
        "# Prior to removing the re-parametrization:\n",
        "print(list(module.named_parameters()))\n",
        "######################################################################\n",
        "print(list(module.named_buffers()))\n",
        "######################################################################\n",
        "print(module.weight)\n",
        "\n",
        "######################################################################\n",
        "# After removing the re-parametrization:\n",
        "prune.remove(module, 'weight')\n",
        "print(list(module.named_parameters()))\n",
        "######################################################################\n",
        "print(list(module.named_buffers()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.2138,  0.1507,  0.1297],\n",
            "          [-0.0887, -0.3002, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.2232,  0.0195],\n",
            "          [ 0.2123, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.1297,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.1988, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.1998,  0.1009, -0.0759],\n",
            "          [-0.0180,  0.0602, -0.2492],\n",
            "          [ 0.0734, -0.2812, -0.0847]]],\n",
            "\n",
            "\n",
            "        [[[-0.0311,  0.3279, -0.1438],\n",
            "          [-0.2013, -0.1219, -0.0993],\n",
            "          [ 0.1979,  0.0930, -0.0901]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.2402, -0.1435],\n",
            "          [ 0.2260,  0.0478,  0.1106],\n",
            "          [ 0.0376,  0.0913, -0.1595]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.2093, -0.2762,  0.2606, -0.2037,  0.1396, -0.3161],\n",
            "       requires_grad=True))]\n",
            "[('weight_mask', tensor([[[[0., 0., 1.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [0., 1., 1.],\n",
            "          [1., 0., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]]])), ('bias_mask', tensor([0., 1., 1., 0., 0., 1.]))]\n",
            "tensor([[[[ 0.0000,  0.0000,  0.1297],\n",
            "          [-0.0887, -0.0000, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.0000,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.0000, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]]], grad_fn=<MulBackward0>)\n",
            "[('bias_orig', Parameter containing:\n",
            "tensor([ 0.2093, -0.2762,  0.2606, -0.2037,  0.1396, -0.3161],\n",
            "       requires_grad=True)), ('weight', Parameter containing:\n",
            "tensor([[[[ 0.0000,  0.0000,  0.1297],\n",
            "          [-0.0887, -0.0000, -0.2179],\n",
            "          [ 0.1616, -0.2809, -0.2802]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1787, -0.0000,  0.0000],\n",
            "          [ 0.0000, -0.2549,  0.2789],\n",
            "          [ 0.2916, -0.0000,  0.2314]]],\n",
            "\n",
            "\n",
            "        [[[-0.1468, -0.0000, -0.0314],\n",
            "          [ 0.2852,  0.0238,  0.1755],\n",
            "          [-0.0203,  0.2721, -0.1099]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]]], requires_grad=True))]\n",
            "[('bias_mask', tensor([0., 1., 1., 0., 0., 1.]))]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9CVJQUWDmNN",
        "colab_type": "code",
        "outputId": "5700b723-afd5-4304-d3d0-5f8c67982a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "######################################################################\n",
        "# Pruning multiple parameters in a model \n",
        "# --------------------------------------\n",
        "#\n",
        "# By specifying the desired pruning technique and parameters, we can easily \n",
        "# prune multiple tensors in a network, perhaps according to their type, as we \n",
        "# will see in this example.\n",
        "\n",
        "new_model = LeNet()\n",
        "for name, module in new_model.named_modules():\n",
        "    # prune 20% of connections in all 2D-conv layers \n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.2)\n",
        "    # prune 40% of connections in all linear layers \n",
        "    elif isinstance(module, torch.nn.Linear):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.4)\n",
        "\n",
        "print(dict(new_model.named_buffers()).keys())  # to verify that all masks exist\n",
        "\n",
        "######################################################################\n",
        "# Global pruning\n",
        "# --------------\n",
        "#\n",
        "# So far, we only looked at what is usually referred to as \"local\" pruning,\n",
        "# i.e. the practice of pruning tensors in a model one by one, by \n",
        "# comparing the statistics (weight magnitude, activation, gradient, etc.) of \n",
        "# each entry exclusively to the other entries in that tensor. However, a \n",
        "# common and perhaps more powerful technique is to prune the model all at \n",
        "# once, by removing (for example) the lowest 20% of connections across the \n",
        "# whole model, instead of removing the lowest 20% of connections in each \n",
        "# layer. This is likely to result in different pruning percentages per layer.\n",
        "# Let's see how to do that using ``global_unstructured`` from \n",
        "# ``torch.nn.utils.prune``.\n",
        "\n",
        "model = LeNet()\n",
        "\n",
        "parameters_to_prune = (\n",
        "    (model.conv1, 'weight'),\n",
        "    (model.conv2, 'weight'),\n",
        "    (model.fc1, 'weight'),\n",
        "    (model.fc2, 'weight'),\n",
        "    (model.fc3, 'weight'),\n",
        ")\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")\n",
        "\n",
        "######################################################################\n",
        "# Now we can check the sparsity induced in every pruned parameter, which will \n",
        "# not be equal to 20% in each layer. However, the global sparsity will be \n",
        "# (approximately) 20%.\n",
        "print(\n",
        "    \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv1.weight == 0))\n",
        "        / float(model.conv1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.conv2.weight == 0))\n",
        "        / float(model.conv2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc1.weight == 0))\n",
        "        / float(model.fc1.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc2.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc2.weight == 0))\n",
        "        / float(model.fc2.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Sparsity in fc3.weight: {:.2f}%\".format(\n",
        "        100. * float(torch.sum(model.fc3.weight == 0))\n",
        "        / float(model.fc3.weight.nelement())\n",
        "    )\n",
        ")\n",
        "print(\n",
        "    \"Global sparsity: {:.2f}%\".format(\n",
        "        100. * float(\n",
        "            torch.sum(model.conv1.weight == 0)\n",
        "            + torch.sum(model.conv2.weight == 0)\n",
        "            + torch.sum(model.fc1.weight == 0)\n",
        "            + torch.sum(model.fc2.weight == 0)\n",
        "            + torch.sum(model.fc3.weight == 0)\n",
        "        )\n",
        "        / float(\n",
        "            model.conv1.weight.nelement()\n",
        "            + model.conv2.weight.nelement()\n",
        "            + model.fc1.weight.nelement()\n",
        "            + model.fc2.weight.nelement()\n",
        "            + model.fc3.weight.nelement()\n",
        "        )\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n",
            "Sparsity in conv1.weight: 0.00%\n",
            "Sparsity in conv2.weight: 8.80%\n",
            "Sparsity in fc1.weight: 22.05%\n",
            "Sparsity in fc2.weight: 12.34%\n",
            "Sparsity in fc3.weight: 7.74%\n",
            "Global sparsity: 20.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yweao9q0bIEm",
        "colab_type": "code",
        "outputId": "860fbef1-aa94-40a0-caf5-402a0a465a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "######################################################################\n",
        "# Extending ``torch.nn.utils.prune`` with custom pruning functions\n",
        "# ------------------------------------------------------------------\n",
        "# To implement your own pruning function, you can extend the\n",
        "# ``nn.utils.prune`` module by subclassing the ``BasePruningMethod``\n",
        "# base class, the same way all other pruning methods do. The base class\n",
        "# implements the following methods for you: ``__call__``, ``apply_mask``,\n",
        "# ``apply``, ``prune``, and ``remove``. Beyond some special cases, you shouldn't\n",
        "# have to reimplement these methods for your new pruning technique.\n",
        "# You will, however, have to implement ``__init__`` (the constructor),\n",
        "# and ``compute_mask`` (the instructions on how to compute the mask\n",
        "# for the given tensor according to the logic of your pruning\n",
        "# technique). In addition, you will have to specify which type of\n",
        "# pruning this technique implements (supported options are ``global``,\n",
        "# ``structured``, and ``unstructured``). This is needed to determine\n",
        "# how to combine masks in the case in which pruning is applied\n",
        "# iteratively. In other words, when pruning a pre-pruned parameter,\n",
        "# the current prunining techique is expected to act on the unpruned\n",
        "# portion of the parameter. Specifying the ``PRUNING_TYPE`` will\n",
        "# enable the ``PruningContainer`` (which handles the iterative\n",
        "# application of pruning masks) to correctly identify the slice of the\n",
        "# parameter to prune.\n",
        "#\n",
        "# Let's assume, for example, that you want to implement a pruning\n",
        "# technique that prunes every other entry in a tensor (or -- if the\n",
        "# tensor has previously been pruned -- in the remaining unpruned\n",
        "# portion of the tensor). This will be of ``PRUNING_TYPE='unstructured'``\n",
        "# because it acts on individual connections in a layer and not on entire\n",
        "# units/channels (``'structured'``), or across different parameters\n",
        "# (``'global'``).\n",
        "\n",
        "class FooBarPruningMethod(prune.BasePruningMethod):\n",
        "    \"\"\"Prune every other entry in a tensor\n",
        "    \"\"\"\n",
        "    PRUNING_TYPE = 'unstructured'\n",
        "\n",
        "    def compute_mask(self, t, default_mask):\n",
        "        mask = default_mask.clone()\n",
        "        mask.view(-1)[::2] = 0 \n",
        "        return mask\n",
        "\n",
        "######################################################################\n",
        "# Now, to apply this to a parameter in an ``nn.Module``, you should\n",
        "# also provide a simple function that instantiates the method and\n",
        "# applies it.\n",
        "def foobar_unstructured(module, name):\n",
        "    \"\"\"Prunes tensor corresponding to parameter called `name` in `module`\n",
        "    by removing every other entry in the tensors.\n",
        "    Modifies module in place (and also return the modified module) \n",
        "    by:\n",
        "    1) adding a named buffer called `name+'_mask'` corresponding to the \n",
        "    binary mask applied to the parameter `name` by the pruning method.\n",
        "    The parameter `name` is replaced by its pruned version, while the \n",
        "    original (unpruned) parameter is stored in a new parameter named \n",
        "    `name+'_orig'`.\n",
        "\n",
        "    Args:\n",
        "        module (nn.Module): module containing the tensor to prune\n",
        "        name (string): parameter name within `module` on which pruning\n",
        "                will act.\n",
        "\n",
        "    Returns:\n",
        "        module (nn.Module): modified (i.e. pruned) version of the input\n",
        "            module\n",
        "    \n",
        "    Examples:\n",
        "        >>> m = nn.Linear(3, 4)\n",
        "        >>> foobar_unstructured(m, name='bias')\n",
        "    \"\"\"\n",
        "    FooBarPruningMethod.apply(module, name)\n",
        "    return module\n",
        "\n",
        "######################################################################\n",
        "# Let's try it out!\n",
        "model = LeNet()\n",
        "foobar_unstructured(model.fc3, name='bias')\n",
        "\n",
        "print(model.fc3.bias_mask)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('weight', Parameter containing:\n",
            "tensor([[[[ 0.0960,  0.1990, -0.3284],\n",
            "          [-0.0901, -0.0498,  0.2432],\n",
            "          [ 0.0512,  0.1423, -0.1570]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.2889,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0130, -0.1306],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.1637, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.1492,  0.1220, -0.0337],\n",
            "          [-0.1939,  0.2457, -0.1599],\n",
            "          [-0.2925,  0.1766,  0.1953]]],\n",
            "\n",
            "\n",
            "        [[[-0.0476,  0.2885, -0.0508],\n",
            "          [ 0.2852, -0.2461,  0.2614],\n",
            "          [-0.2236, -0.1489,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0094],\n",
            "          [-0.2870,  0.0434, -0.2159],\n",
            "          [-0.3075, -0.0028, -0.2630]]]], requires_grad=True)), ('bias', Parameter containing:\n",
            "tensor([ 0.0297,  0.3308,  0.3307,  0.2654, -0.1183, -0.1151],\n",
            "       requires_grad=True))]\n",
            "[]\n",
            "[('bias', Parameter containing:\n",
            "tensor([ 0.0297,  0.3308,  0.3307,  0.2654, -0.1183, -0.1151],\n",
            "       requires_grad=True)), ('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.0960,  0.1990, -0.3284],\n",
            "          [-0.0901, -0.0498,  0.2432],\n",
            "          [ 0.0512,  0.1423, -0.1570]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.2889,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0130, -0.1306],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.1637, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.1492,  0.1220, -0.0337],\n",
            "          [-0.1939,  0.2457, -0.1599],\n",
            "          [-0.2925,  0.1766,  0.1953]]],\n",
            "\n",
            "\n",
            "        [[[-0.0476,  0.2885, -0.0508],\n",
            "          [ 0.2852, -0.2461,  0.2614],\n",
            "          [-0.2236, -0.1489,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0094],\n",
            "          [-0.2870,  0.0434, -0.2159],\n",
            "          [-0.3075, -0.0028, -0.2630]]]], requires_grad=True))]\n",
            "[('weight_mask', tensor([[[[1., 1., 0.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1.],\n",
            "          [0., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [1., 1., 0.]]]]))]\n",
            "tensor([[[[ 0.0960,  0.1990, -0.0000],\n",
            "          [-0.0901, -0.0498,  0.2432],\n",
            "          [ 0.0000,  0.1423, -0.1570]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.0000,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0000, -0.0000],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.0000, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.1492,  0.1220, -0.0000],\n",
            "          [-0.1939,  0.0000, -0.1599],\n",
            "          [-0.2925,  0.1766,  0.1953]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.2885, -0.0508],\n",
            "          [ 0.0000, -0.2461,  0.2614],\n",
            "          [-0.0000, -0.1489,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.3075, -0.0028, -0.0000]]]], grad_fn=<MulBackward0>)\n",
            "OrderedDict([(14, <torch.nn.utils.prune.RandomUnstructured object at 0x7f8d45687160>)])\n",
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.0960,  0.1990, -0.3284],\n",
            "          [-0.0901, -0.0498,  0.2432],\n",
            "          [ 0.0512,  0.1423, -0.1570]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.2889,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0130, -0.1306],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.1637, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.1492,  0.1220, -0.0337],\n",
            "          [-0.1939,  0.2457, -0.1599],\n",
            "          [-0.2925,  0.1766,  0.1953]]],\n",
            "\n",
            "\n",
            "        [[[-0.0476,  0.2885, -0.0508],\n",
            "          [ 0.2852, -0.2461,  0.2614],\n",
            "          [-0.2236, -0.1489,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0094],\n",
            "          [-0.2870,  0.0434, -0.2159],\n",
            "          [-0.3075, -0.0028, -0.2630]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.0297,  0.3308,  0.3307,  0.2654, -0.1183, -0.1151],\n",
            "       requires_grad=True))]\n",
            "[('weight_mask', tensor([[[[1., 1., 0.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 1., 1.],\n",
            "          [0., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [1., 1., 0.]]]])), ('bias_mask', tensor([0., 1., 1., 1., 0., 0.]))]\n",
            "tensor([0.0000, 0.3308, 0.3307, 0.2654, -0.0000, -0.0000],\n",
            "       grad_fn=<MulBackward0>)\n",
            "OrderedDict([(14, <torch.nn.utils.prune.RandomUnstructured object at 0x7f8d45687160>), (15, <torch.nn.utils.prune.L1Unstructured object at 0x7f8d275cc6d8>)])\n",
            "tensor([[[[ 0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.0000,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0000, -0.0000],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.0000, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.3075, -0.0028, -0.0000]]]], grad_fn=<MulBackward0>)\n",
            "[<torch.nn.utils.prune.RandomUnstructured object at 0x7f8d45687160>, <torch.nn.utils.prune.LnStructured object at 0x7f8cda9f9b00>]\n",
            "odict_keys(['conv1.weight_orig', 'conv1.bias_orig', 'conv1.weight_mask', 'conv1.bias_mask', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias'])\n",
            "[('weight_orig', Parameter containing:\n",
            "tensor([[[[ 0.0960,  0.1990, -0.3284],\n",
            "          [-0.0901, -0.0498,  0.2432],\n",
            "          [ 0.0512,  0.1423, -0.1570]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.2889,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0130, -0.1306],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.1637, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.1492,  0.1220, -0.0337],\n",
            "          [-0.1939,  0.2457, -0.1599],\n",
            "          [-0.2925,  0.1766,  0.1953]]],\n",
            "\n",
            "\n",
            "        [[[-0.0476,  0.2885, -0.0508],\n",
            "          [ 0.2852, -0.2461,  0.2614],\n",
            "          [-0.2236, -0.1489,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0094],\n",
            "          [-0.2870,  0.0434, -0.2159],\n",
            "          [-0.3075, -0.0028, -0.2630]]]], requires_grad=True)), ('bias_orig', Parameter containing:\n",
            "tensor([ 0.0297,  0.3308,  0.3307,  0.2654, -0.1183, -0.1151],\n",
            "       requires_grad=True))]\n",
            "[('weight_mask', tensor([[[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 1.],\n",
            "          [1., 1., 1.],\n",
            "          [1., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[1., 0., 0.],\n",
            "          [1., 1., 1.],\n",
            "          [0., 1., 1.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [0., 0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[1., 1., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [1., 1., 0.]]]])), ('bias_mask', tensor([0., 1., 1., 1., 0., 0.]))]\n",
            "tensor([[[[ 0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.0000,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0000, -0.0000],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.0000, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.3075, -0.0028, -0.0000]]]], grad_fn=<MulBackward0>)\n",
            "[('bias_orig', Parameter containing:\n",
            "tensor([ 0.0297,  0.3308,  0.3307,  0.2654, -0.1183, -0.1151],\n",
            "       requires_grad=True)), ('weight', Parameter containing:\n",
            "tensor([[[[ 0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000],\n",
            "          [ 0.0000,  0.0000, -0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.1582,  0.0000,  0.3102],\n",
            "          [ 0.1464, -0.2813, -0.0036],\n",
            "          [ 0.2368, -0.2903,  0.1698]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2098,  0.0000, -0.0000],\n",
            "          [-0.2480, -0.2332, -0.1625],\n",
            "          [-0.0000, -0.3274, -0.2308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.0000,  0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.0000,  0.0000, -0.0000],\n",
            "          [ 0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000, -0.0000,  0.0000]]],\n",
            "\n",
            "\n",
            "        [[[-0.2876, -0.3044,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000],\n",
            "          [-0.3075, -0.0028, -0.0000]]]], requires_grad=True))]\n",
            "[('bias_mask', tensor([0., 1., 1., 1., 0., 0.]))]\n",
            "dict_keys(['conv1.weight_mask', 'conv2.weight_mask', 'fc1.weight_mask', 'fc2.weight_mask', 'fc3.weight_mask'])\n",
            "Sparsity in conv1.weight: 3.70%\n",
            "Sparsity in conv2.weight: 8.80%\n",
            "Sparsity in fc1.weight: 22.13%\n",
            "Sparsity in fc2.weight: 11.61%\n",
            "Sparsity in fc3.weight: 11.79%\n",
            "Global sparsity: 20.00%\n",
            "tensor([0., 1., 0., 1., 0., 1., 0., 1., 0., 1.])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}